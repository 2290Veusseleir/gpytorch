{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GP Regression with an RBF Kernel\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we demonstrate many of the design features of GPyTorch using the simplest example, training an RBF kernel Gaussian process on a simple function. We'll be modeling the function $$y = \\sin(2\\pi x) + \\epsilon$$ $$\\epsilon \\sim \\mathcal{N}(0, 0.2)$$ with 11 training examples, and testing on 51 test examples.\n",
    "\n",
    "**Note:** this notebook is not necessarily intended to teach the mathematical background of Gaussian processes, but rather how to train a simple one and make predictions in GPyTorch. For a mathematical treatment, Chapter 2 of Gaussian Processes for Machine Learning provides a very thorough introduction to GP regression (this entire text is highly recommended): http://www.gaussianprocess.org/gpml/chapters/RW2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.priors import SmoothedBoxPrior\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training data\n",
    "\n",
    "In the next cell, we set up the training data for this example. We'll be using 11 regularly spaced points on [0,1] which we evaluate the function on and add Gaussian noise to get the training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 11 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 100)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x.data * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "\n",
    "The next cell demonstrates the most critical features of a user-defined Gaussian process model in GPyTorch. Building a GP model in GPyTorch is different in a number of ways.\n",
    "\n",
    "First in contrast to many existing GP packages, we do not provide full GP models for the user. Rather, we provide *the tools necessary to quickly construct one*. This is because we believe, analogous to building a neural network in standard PyTorch, it is important to have the flexibility to include whatever components are necessary. As can be seen in more complicated examples, like the `dkl_mnist.ipynb` example which combines deep learning and Gaussian processes, this allows the user great flexibility in designing custom models.\n",
    "\n",
    "The components of a user built (Exact, i.e. non-variational) GP model in GPyTorch are, broadly speaking:\n",
    "\n",
    "1. An `__init__` method that takes the training data and a likelihood, and constructs whatever objects are necessary for the model's `forward` method. This will most commonly include things like a mean module and a kernel module, but may also include things like extra parameters, such as a log outputscale that we will see in later examples.\n",
    "\n",
    "2. A `forward` method that takes in some $n \\times d$ data `x` and returns a GaussianRandomVariable with the *prior* mean and covariance evaluated at `x`. In other words, we return the vector $\\mu(x)$ and the $n \\times n$ matrix $K_{xx}$ representing the prior mean and covariance matrix of the GP. \n",
    "\n",
    "This specification leaves a large amount of flexibility when defining a model. For example, to compose two kernels via addition, you can either add the kernel modules directly:\n",
    "\n",
    "```python\n",
    "self.covar_module = RBFKernel() + WhiteNoiseKernel()\n",
    "```\n",
    "\n",
    "Or you can add the outputs of the kernel in the forward method:\n",
    "\n",
    "```python\n",
    "covar_x = self.rbf_kernel_module(x) + self.white_noise_module(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.covar_module = RBFKernel()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return GaussianRandomVariable(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = GaussianLikelihood()\n",
    "model = ExactGPModel(train_x.data, train_y.data, likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "In the next cell, we handle using Type-II MLE to train the hyperparameters of the Gaussian process.\n",
    "\n",
    "The most obvious difference here compared to many other GP implementations is that, as in standard PyTorch, the core training loop is written by the user. In GPyTorch, we make use of the standard PyTorch optimizers as from `torch.optim`, and all trainable parameters of the model should be of type `torch.nn.Parameter`. Because GP models directly extend `torch.nn.Module`, calls to methods like `model.parameters()` or `model.named_parameters()` function as you might expect coming from PyTorch.\n",
    "\n",
    "In most cases, the boilerplate code below will work well. It has the same basic components as the standard PyTorch training loop:\n",
    "\n",
    "1. Zero all parameter gradients\n",
    "2. Call the model and compute the loss\n",
    "3. Call backward on the loss to fill in gradients\n",
    "4. Take a step on the optimizer\n",
    "\n",
    "However, defining custom training loops allows for greater flexibility. For example, it is easy to save the parameters at each step of training, or use different learning rates for different parameters (which may be useful in deep kernel learning for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 1.076   log_lengthscale: 0.000   log_noise: 0.000\n",
      "Iter 2/50 - Loss: 1.035   log_lengthscale: -0.100   log_noise: -0.100\n",
      "Iter 3/50 - Loss: 0.994   log_lengthscale: -0.200   log_noise: -0.200\n",
      "Iter 4/50 - Loss: 0.953   log_lengthscale: -0.299   log_noise: -0.300\n",
      "Iter 5/50 - Loss: 0.912   log_lengthscale: -0.399   log_noise: -0.400\n",
      "Iter 6/50 - Loss: 0.867   log_lengthscale: -0.498   log_noise: -0.499\n",
      "Iter 7/50 - Loss: 0.819   log_lengthscale: -0.597   log_noise: -0.599\n",
      "Iter 8/50 - Loss: 0.765   log_lengthscale: -0.696   log_noise: -0.698\n",
      "Iter 9/50 - Loss: 0.707   log_lengthscale: -0.793   log_noise: -0.798\n",
      "Iter 10/50 - Loss: 0.649   log_lengthscale: -0.892   log_noise: -0.899\n",
      "Iter 11/50 - Loss: 0.592   log_lengthscale: -0.992   log_noise: -1.000\n",
      "Iter 12/50 - Loss: 0.541   log_lengthscale: -1.092   log_noise: -1.101\n",
      "Iter 13/50 - Loss: 0.496   log_lengthscale: -1.188   log_noise: -1.202\n",
      "Iter 14/50 - Loss: 0.455   log_lengthscale: -1.277   log_noise: -1.304\n",
      "Iter 15/50 - Loss: 0.417   log_lengthscale: -1.357   log_noise: -1.406\n",
      "Iter 16/50 - Loss: 0.383   log_lengthscale: -1.424   log_noise: -1.508\n",
      "Iter 17/50 - Loss: 0.345   log_lengthscale: -1.481   log_noise: -1.610\n",
      "Iter 18/50 - Loss: 0.313   log_lengthscale: -1.528   log_noise: -1.711\n",
      "Iter 19/50 - Loss: 0.282   log_lengthscale: -1.564   log_noise: -1.812\n",
      "Iter 20/50 - Loss: 0.253   log_lengthscale: -1.588   log_noise: -1.913\n",
      "Iter 21/50 - Loss: 0.218   log_lengthscale: -1.596   log_noise: -2.013\n",
      "Iter 22/50 - Loss: 0.188   log_lengthscale: -1.596   log_noise: -2.113\n",
      "Iter 23/50 - Loss: 0.154   log_lengthscale: -1.587   log_noise: -2.212\n",
      "Iter 24/50 - Loss: 0.127   log_lengthscale: -1.567   log_noise: -2.309\n",
      "Iter 25/50 - Loss: 0.108   log_lengthscale: -1.542   log_noise: -2.406\n",
      "Iter 26/50 - Loss: 0.071   log_lengthscale: -1.509   log_noise: -2.502\n",
      "Iter 27/50 - Loss: 0.048   log_lengthscale: -1.472   log_noise: -2.596\n",
      "Iter 28/50 - Loss: 0.026   log_lengthscale: -1.428   log_noise: -2.688\n",
      "Iter 29/50 - Loss: 0.010   log_lengthscale: -1.381   log_noise: -2.778\n",
      "Iter 30/50 - Loss: -0.010   log_lengthscale: -1.330   log_noise: -2.866\n",
      "Iter 31/50 - Loss: -0.021   log_lengthscale: -1.280   log_noise: -2.952\n",
      "Iter 32/50 - Loss: -0.025   log_lengthscale: -1.235   log_noise: -3.034\n",
      "Iter 33/50 - Loss: -0.030   log_lengthscale: -1.194   log_noise: -3.114\n",
      "Iter 34/50 - Loss: -0.030   log_lengthscale: -1.155   log_noise: -3.189\n",
      "Iter 35/50 - Loss: -0.025   log_lengthscale: -1.122   log_noise: -3.260\n",
      "Iter 36/50 - Loss: -0.021   log_lengthscale: -1.109   log_noise: -3.326\n",
      "Iter 37/50 - Loss: -0.015   log_lengthscale: -1.105   log_noise: -3.387\n",
      "Iter 38/50 - Loss: -0.002   log_lengthscale: -1.112   log_noise: -3.443\n",
      "Iter 39/50 - Loss: 0.005   log_lengthscale: -1.126   log_noise: -3.493\n",
      "Iter 40/50 - Loss: 0.017   log_lengthscale: -1.150   log_noise: -3.536\n",
      "Iter 41/50 - Loss: 0.032   log_lengthscale: -1.175   log_noise: -3.574\n",
      "Iter 42/50 - Loss: 0.049   log_lengthscale: -1.202   log_noise: -3.604\n",
      "Iter 43/50 - Loss: 0.061   log_lengthscale: -1.229   log_noise: -3.629\n",
      "Iter 44/50 - Loss: 0.071   log_lengthscale: -1.246   log_noise: -3.647\n",
      "Iter 45/50 - Loss: 0.093   log_lengthscale: -1.274   log_noise: -3.659\n",
      "Iter 46/50 - Loss: 0.113   log_lengthscale: -1.294   log_noise: -3.665\n",
      "Iter 47/50 - Loss: 0.112   log_lengthscale: -1.299   log_noise: -3.665\n",
      "Iter 48/50 - Loss: 0.122   log_lengthscale: -1.296   log_noise: -3.661\n",
      "Iter 49/50 - Loss: 0.144   log_lengthscale: -1.285   log_noise: -3.653\n",
      "Iter 50/50 - Loss: 0.146   log_lengthscale: -1.260   log_noise: -3.640\n"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 50\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   log_lengthscale: %.3f   log_noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.data[0],\n",
    "        model.covar_module.log_lengthscale.data[0, 0],\n",
    "        model.likelihood.log_noise.data[0]\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions with the model\n",
    "\n",
    "In the next cell, we make predictions with the model. To do this, we simply put the model and likelihood in eval mode, and call both modules on the test data.\n",
    "\n",
    "Just as a user defined GP model returns a GaussianRandomVariable containing the prior mean and covariance from forward, a trained GP model in eval mode returns a GaussianRandomVariable containing the posterior mean and covariance. Thus, getting the predictive mean and variance, and then sampling functions from the GP at the given test points could be accomplished with calls like:\n",
    "\n",
    "```python\n",
    "f_preds = model(test_x)\n",
    "y_preds = likelihood(model(test_x))\n",
    "f_mean = f_preds.mean()\n",
    "f_var = f_preds.var()\n",
    "f_covar = f_preds.covar()\n",
    "f_samples = f_preds.sample(1000)\n",
    "```\n",
    "\n",
    "The `gpytorch.fast_pred_var` context is not needed, but here we are giving a preview of using one of our cool features, getting faster predictive distributions using LOVE (https://arxiv.org/abs/1803.06058)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put model and likelihood into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "test_x = torch.linspace(0, 1, 51)\n",
    "# Make predictions by feeding model through likelihood\n",
    "with gpytorch.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the model fit\n",
    "\n",
    "In the next cell, we plot the mean and confidence region of the Gaussian process model. The `confidence_region` method is a helper method that returns 2 standard deviations above and below the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAADSCAYAAACo7W6xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0322c7a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize plot\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "# Define plotting function\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = rand_var.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.data.numpy(), rand_var.mean().data.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.data.numpy(), lower.data.numpy(), upper.data.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "# Plot the predictions\n",
    "ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
