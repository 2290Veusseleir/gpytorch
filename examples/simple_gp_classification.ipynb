{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is the simplest form of using an RBF kernel in an `VariationalGP` module for classification. This basic model is usable when there is not much training data and no advanced techniques are required.\n",
    "\n",
    "In this example, weâ€™re modeling a unit wave with period 1/2 centered with positive values @ x=0\n",
    "\n",
    "Variational inference uses the assumption that the posterior distribution factors multiplicatively over the input variables. This makes approximating the distribution via the KL divergence possible to obtain a fast approximation to the posterior. For a good explanation of variational techniques, sections 4-6 of the following may be useful: https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "# Grid points are [0,1] every 1/9\n",
    "train_x = Variable(torch.linspace(0, 1, 10))\n",
    "# Labels are unit wave with period 1/2 centered with positive values @ x=0\n",
    "train_y = Variable(torch.sign(torch.cos(train_x.data * (4 * math.pi))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic classification model with variational inference\n",
    "class GPClassificationModel(gpytorch.models.VariationalGP):\n",
    "    def __init__(self, train_inputs):\n",
    "        super(GPClassificationModel, self).__init__(train_inputs)\n",
    "        # Only non-zero mean function can be learned\n",
    "        self.mean_module = ConstantMean(constant_bounds=[-1e-5,1e-5])\n",
    "        # Use universal approximator RBF kernel\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-5, 6))\n",
    "        self.register_parameter('log_outputscale', nn.Parameter(torch.Tensor([0])), bounds=(-5,6))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # Get predictive mean and covariance\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        # Scale covariance\n",
    "        covar_x = covar_x.mul(self.log_outputscale.exp())\n",
    "        # Package prediction as GaussianRandomVariable\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        # Return predictions\n",
    "        return latent_pred\n",
    "\n",
    "# Initialize model and likelihood\n",
    "model = GPClassificationModel(train_x.data)\n",
    "likelihood = BernoulliLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 297.203   log_lengthscale: 0.000\n",
      "Iter 2/50 - Loss: 207.702   log_lengthscale: -0.100\n",
      "Iter 3/50 - Loss: 135.155   log_lengthscale: -0.199\n",
      "Iter 4/50 - Loss: 86.705   log_lengthscale: -0.298\n",
      "Iter 5/50 - Loss: 55.485   log_lengthscale: -0.396\n",
      "Iter 6/50 - Loss: 34.695   log_lengthscale: -0.493\n",
      "Iter 7/50 - Loss: 22.533   log_lengthscale: -0.589\n",
      "Iter 8/50 - Loss: 17.101   log_lengthscale: -0.684\n",
      "Iter 9/50 - Loss: 14.844   log_lengthscale: -0.777\n",
      "Iter 10/50 - Loss: 15.271   log_lengthscale: -0.869\n",
      "Iter 11/50 - Loss: 15.613   log_lengthscale: -0.959\n",
      "Iter 12/50 - Loss: 15.810   log_lengthscale: -1.048\n",
      "Iter 13/50 - Loss: 14.828   log_lengthscale: -1.135\n",
      "Iter 14/50 - Loss: 13.286   log_lengthscale: -1.219\n",
      "Iter 15/50 - Loss: 11.431   log_lengthscale: -1.302\n",
      "Iter 16/50 - Loss: 9.555   log_lengthscale: -1.382\n",
      "Iter 17/50 - Loss: 8.067   log_lengthscale: -1.460\n",
      "Iter 18/50 - Loss: 6.258   log_lengthscale: -1.536\n",
      "Iter 19/50 - Loss: 5.629   log_lengthscale: -1.610\n",
      "Iter 20/50 - Loss: 5.069   log_lengthscale: -1.680\n",
      "Iter 21/50 - Loss: 4.388   log_lengthscale: -1.747\n",
      "Iter 22/50 - Loss: 4.621   log_lengthscale: -1.811\n",
      "Iter 23/50 - Loss: 3.837   log_lengthscale: -1.872\n",
      "Iter 24/50 - Loss: 3.546   log_lengthscale: -1.930\n",
      "Iter 25/50 - Loss: 3.812   log_lengthscale: -1.985\n",
      "Iter 26/50 - Loss: 3.884   log_lengthscale: -2.036\n",
      "Iter 27/50 - Loss: 3.173   log_lengthscale: -2.084\n",
      "Iter 28/50 - Loss: 2.809   log_lengthscale: -2.130\n",
      "Iter 29/50 - Loss: 3.007   log_lengthscale: -2.172\n",
      "Iter 30/50 - Loss: 2.730   log_lengthscale: -2.211\n",
      "Iter 31/50 - Loss: 2.656   log_lengthscale: -2.247\n",
      "Iter 32/50 - Loss: 2.939   log_lengthscale: -2.281\n",
      "Iter 33/50 - Loss: 2.564   log_lengthscale: -2.312\n",
      "Iter 34/50 - Loss: 2.683   log_lengthscale: -2.340\n",
      "Iter 35/50 - Loss: 2.431   log_lengthscale: -2.366\n",
      "Iter 36/50 - Loss: 2.570   log_lengthscale: -2.390\n",
      "Iter 37/50 - Loss: 2.548   log_lengthscale: -2.412\n",
      "Iter 38/50 - Loss: 2.896   log_lengthscale: -2.432\n",
      "Iter 39/50 - Loss: 2.689   log_lengthscale: -2.451\n",
      "Iter 40/50 - Loss: 2.279   log_lengthscale: -2.467\n",
      "Iter 41/50 - Loss: 2.606   log_lengthscale: -2.482\n",
      "Iter 42/50 - Loss: 2.027   log_lengthscale: -2.496\n",
      "Iter 43/50 - Loss: 2.566   log_lengthscale: -2.507\n",
      "Iter 44/50 - Loss: 2.654   log_lengthscale: -2.517\n",
      "Iter 45/50 - Loss: 2.305   log_lengthscale: -2.527\n",
      "Iter 46/50 - Loss: 2.038   log_lengthscale: -2.535\n",
      "Iter 47/50 - Loss: 2.395   log_lengthscale: -2.542\n",
      "Iter 48/50 - Loss: 1.934   log_lengthscale: -2.549\n",
      "Iter 49/50 - Loss: 2.770   log_lengthscale: -2.554\n",
      "Iter 50/50 - Loss: 2.290   log_lengthscale: -2.559\n"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "    # BernoulliLikelihood has no parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "# n_data refers to the amount of training data\n",
    "mll = gpytorch.mlls.VariationalMarginalLogLikelihood(likelihood, model, n_data=len(train_y))\n",
    "\n",
    "training_iter = 50\n",
    "for i in range(training_iter):\n",
    "    # Zero backpropped gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Get predictive output\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   log_lengthscale: %.3f' % (\n",
    "        i + 1, training_iter, loss.data[0],\n",
    "        model.covar_module.log_lengthscale.data.squeeze()[0],\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1eab0ac3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Go into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize fig and axes for plot\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "# Test x are regularly spaced by 0.01 0,1 inclusive\n",
    "test_x = Variable(torch.linspace(0, 1, 101))\n",
    "## Not sure why this is with... Get Bernoulli prediction\n",
    "with gpytorch.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "# Plotting function\n",
    "# A lot of this should be consolidated as helper between different notebooks\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    pred_labels = rand_var.mean().ge(0.5).float().mul(2).sub(1)\n",
    "    ax.plot(test_x.data.numpy(), pred_labels.data.numpy(), 'b')\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "# Plot square wave predictions\n",
    "ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
