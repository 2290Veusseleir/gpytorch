{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "train_x = Variable(torch.linspace(0, 1, 15))\n",
    "train_y = Variable(torch.sign(torch.cos(train_x.data * (2 * math.pi))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GPClassificationModel(gpytorch.GPModel):\n",
    "    def __init__(self):\n",
    "        super(GPClassificationModel,self).__init__(BernoulliLikelihood())\n",
    "        self.mean_module = ConstantMean(constant_bounds=(-1, 1))\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-3, 3))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return GaussianRandomVariable(mean_x, covar_x)\n",
    "\n",
    "prior_model = GPClassificationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_and_predictions(model, plot_train_data=True):\n",
    "    f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    test_x = Variable(torch.linspace(0, 1, 51))\n",
    "    observed_pred = model(test_x)\n",
    "\n",
    "    def ax_plot(ax, rand_var, title):\n",
    "        if plot_train_data:\n",
    "            ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "        pred_labels = rand_var.mean().ge(0.5).float().mul(2).sub(1)\n",
    "        ax.plot(test_x.data.numpy(), pred_labels.data.numpy(), 'b')\n",
    "        ax.set_ylim([-3, 3])\n",
    "        ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAADNCAYAAABXc664AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAZNKhdliEhECAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1132e7ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plot_model_and_predictions(prior_model, plot_train_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/20 - Loss: nan   log_lengthscale: 0.000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Lapack Error syev : 13 off-diagonal elements didn't converge to zero at /Users/soumith/miniconda2/conda-bld/pytorch_1501999754274/work/torch/lib/TH/generic/THTensorLapack.c:384",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-27a87092246e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mposterior_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarginal_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gpleiss/Dropbox/workspace/gpytorch/gpytorch/inference/posterior_models/variational_gp_posterior.pyc\u001b[0m in \u001b[0;36mmarginal_log_likelihood\u001b[0;34m(self, output, train_y, num_samples)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         kl_divergence = gpytorch.mvn_kl_divergence(self.variational_mean,\n\u001b[0;32m--> 102\u001b[0;31m                                                    chol_var_covar, inducing_mean, inducing_covar)\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gpleiss/Dropbox/workspace/gpytorch/gpytorch/__init__.pyc\u001b[0m in \u001b[0;36mmvn_kl_divergence\u001b[0;34m(mean_1, chol_covar_1, mean_2, covar_2)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;31m# Multiplying that by -2 gives us two of the terms in the KL divergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# (plus an unwanted constant that we can subtract out).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mK_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexact_gp_marginal_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovar_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_diffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Get logdet(\\Sigma_{1})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gpleiss/Dropbox/workspace/gpytorch/gpytorch/__init__.pyc\u001b[0m in \u001b[0;36mexact_gp_marginal_log_likelihood\u001b[0;34m(covar, target)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgp_marginal_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mExactGPMarginalLogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gpleiss/Dropbox/workspace/gpytorch/gpytorch/functions/exact_gp_marginal_log_likelihood.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, matrix, y)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_inv_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Log determinant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStochasticLQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_random_probes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmv_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mld\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gpleiss/Dropbox/workspace/gpytorch/gpytorch/utils/lanczos_quadrature.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, A, n, funcs)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;31m# O(n^2) time/convergence with QR iteration,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# or O(n log n) with fast multipole (TODO).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymeig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Lapack Error syev : 13 off-diagonal elements didn't converge to zero at /Users/soumith/miniconda2/conda-bld/pytorch_1501999754274/work/torch/lib/TH/generic/THTensorLapack.c:384"
     ]
    }
   ],
   "source": [
    "from gpytorch.inference import Inference\n",
    "infer = Inference(prior_model)\n",
    "posterior_model = infer.run(train_x, train_y)\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "posterior_model.train()\n",
    "optimizer = optim.Adam(posterior_model.parameters(), lr=0.01)\n",
    "optimizer.n_iter = 0\n",
    "for i in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    output = posterior_model.forward(train_x)\n",
    "    loss = -posterior_model.marginal_log_likelihood(output, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.n_iter += 1\n",
    "    print('Iter %d/20 - Loss: %.3f   log_lengthscale: %.3f' % (\n",
    "        i + 1, loss.data[0],\n",
    "        posterior_model.prior_model.covar_module.log_lengthscale.data.squeeze()[0],\n",
    "    ))\n",
    "    optimizer.step()\n",
    "    \n",
    "# Set back to eval mode\n",
    "posterior_model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = plot_model_and_predictions(posterior_model)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
