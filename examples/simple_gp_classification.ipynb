{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is the simplest form of using an RBF kernel in an `VariationalGP` module for classification. This basic model is usable when there is not much training data and no advanced techniques are required.\n",
    "\n",
    "In this example, weâ€™re modeling a unit wave with period 1/2 centered with positive values @ x=0\n",
    "\n",
    "Variational inference uses the assumption that the posterior distribution factors multiplicatively over the input variables. This makes approximating the distribution via the KL divergence possible to obtain a fast approximation to the posterior. For a good explanation of variational techniques, sections 4-6 of the following may be useful: https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "# Grid points are [0,1] every 1/9\n",
    "train_x = Variable(torch.linspace(0, 1, 10))\n",
    "# Labels are unit wave with period 1/2 centered with positive values @ x=0\n",
    "train_y = Variable(torch.sign(torch.cos(train_x.data * (4 * math.pi))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.priors import SmoothedBoxPrior\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic classification model with variational inference\n",
    "class GPClassificationModel(gpytorch.models.VariationalGP):\n",
    "    def __init__(self, train_x):\n",
    "        super(GPClassificationModel, self).__init__(train_x)\n",
    "        self.mean_module = ConstantMean(prior=SmoothedBoxPrior(-1e-5, 1e-5))\n",
    "        self.covar_module = RBFKernel(\n",
    "            log_lengthscale_prior=SmoothedBoxPrior(math.exp(-5), math.exp(6), sigma=0.1, log_transform=True)\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"log_outputscale\",\n",
    "            parameter=torch.nn.Parameter(torch.Tensor([0])),\n",
    "            prior=SmoothedBoxPrior(math.exp(-5), math.exp(6), sigma=0.1, log_transform=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x) * self.log_outputscale.exp()\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "# Initialize model and likelihood\n",
    "model = GPClassificationModel(train_x.data)\n",
    "likelihood = BernoulliLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 326.092   log_lengthscale: 0.000\n",
      "Iter 2/50 - Loss: 229.205   log_lengthscale: -0.100\n",
      "Iter 3/50 - Loss: 147.732   log_lengthscale: -0.200\n",
      "Iter 4/50 - Loss: 94.309   log_lengthscale: -0.297\n",
      "Iter 5/50 - Loss: 58.450   log_lengthscale: -0.393\n",
      "Iter 6/50 - Loss: 34.128   log_lengthscale: -0.487\n",
      "Iter 7/50 - Loss: 20.241   log_lengthscale: -0.579\n",
      "Iter 8/50 - Loss: 14.262   log_lengthscale: -0.669\n",
      "Iter 9/50 - Loss: 12.604   log_lengthscale: -0.757\n",
      "Iter 10/50 - Loss: 12.035   log_lengthscale: -0.842\n",
      "Iter 11/50 - Loss: 11.015   log_lengthscale: -0.924\n",
      "Iter 12/50 - Loss: 10.255   log_lengthscale: -1.004\n",
      "Iter 13/50 - Loss: 9.753   log_lengthscale: -1.081\n",
      "Iter 14/50 - Loss: 9.735   log_lengthscale: -1.155\n",
      "Iter 15/50 - Loss: 7.783   log_lengthscale: -1.227\n",
      "Iter 16/50 - Loss: 6.957   log_lengthscale: -1.297\n",
      "Iter 17/50 - Loss: 5.993   log_lengthscale: -1.363\n",
      "Iter 18/50 - Loss: 5.237   log_lengthscale: -1.427\n",
      "Iter 19/50 - Loss: 4.902   log_lengthscale: -1.487\n",
      "Iter 20/50 - Loss: 4.965   log_lengthscale: -1.544\n",
      "Iter 21/50 - Loss: 4.777   log_lengthscale: -1.597\n",
      "Iter 22/50 - Loss: 4.574   log_lengthscale: -1.647\n",
      "Iter 23/50 - Loss: 4.703   log_lengthscale: -1.693\n",
      "Iter 24/50 - Loss: 5.116   log_lengthscale: -1.736\n",
      "Iter 25/50 - Loss: 4.525   log_lengthscale: -1.775\n",
      "Iter 26/50 - Loss: 4.528   log_lengthscale: -1.812\n",
      "Iter 27/50 - Loss: 4.624   log_lengthscale: -1.846\n",
      "Iter 28/50 - Loss: 4.620   log_lengthscale: -1.877\n",
      "Iter 29/50 - Loss: 4.564   log_lengthscale: -1.905\n",
      "Iter 30/50 - Loss: 4.861   log_lengthscale: -1.931\n",
      "Iter 31/50 - Loss: 4.773   log_lengthscale: -1.954\n",
      "Iter 32/50 - Loss: 4.270   log_lengthscale: -1.976\n",
      "Iter 33/50 - Loss: 4.927   log_lengthscale: -1.995\n",
      "Iter 34/50 - Loss: 4.501   log_lengthscale: -2.012\n",
      "Iter 35/50 - Loss: 4.371   log_lengthscale: -2.028\n",
      "Iter 36/50 - Loss: 4.359   log_lengthscale: -2.042\n",
      "Iter 37/50 - Loss: 4.372   log_lengthscale: -2.054\n",
      "Iter 38/50 - Loss: 4.390   log_lengthscale: -2.065\n",
      "Iter 39/50 - Loss: 4.958   log_lengthscale: -2.075\n",
      "Iter 40/50 - Loss: 4.401   log_lengthscale: -2.084\n",
      "Iter 41/50 - Loss: 4.529   log_lengthscale: -2.092\n",
      "Iter 42/50 - Loss: 4.274   log_lengthscale: -2.099\n",
      "Iter 43/50 - Loss: 4.380   log_lengthscale: -2.105\n",
      "Iter 44/50 - Loss: 4.652   log_lengthscale: -2.110\n",
      "Iter 45/50 - Loss: 4.246   log_lengthscale: -2.115\n",
      "Iter 46/50 - Loss: 4.502   log_lengthscale: -2.118\n",
      "Iter 47/50 - Loss: 4.252   log_lengthscale: -2.121\n",
      "Iter 48/50 - Loss: 4.289   log_lengthscale: -2.124\n",
      "Iter 49/50 - Loss: 4.384   log_lengthscale: -2.125\n",
      "Iter 50/50 - Loss: 4.035   log_lengthscale: -2.127\n"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "    # BernoulliLikelihood has no parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "# n_data refers to the amount of training data\n",
    "mll = gpytorch.mlls.VariationalMarginalLogLikelihood(likelihood, model, n_data=len(train_y))\n",
    "\n",
    "training_iter = 50\n",
    "for i in range(training_iter):\n",
    "    # Zero backpropped gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Get predictive output\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   log_lengthscale: %.3f' % (\n",
    "        i + 1, training_iter, loss.data[0],\n",
    "        model.covar_module.log_lengthscale.data.squeeze()[0],\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAADSCAYAAACo7W6xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5d88570f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Go into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize fig and axes for plot\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "# Test x are regularly spaced by 0.01 0,1 inclusive\n",
    "test_x = Variable(torch.linspace(0, 1, 101))\n",
    "## Not sure why this is with... Get Bernoulli prediction\n",
    "with gpytorch.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "# Plotting function\n",
    "# A lot of this should be consolidated as helper between different notebooks\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    pred_labels = rand_var.mean().ge(0.5).float().mul(2).sub(1)\n",
    "    ax.plot(test_x.data.numpy(), pred_labels.data.numpy(), 'b')\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "# Plot square wave predictions\n",
    "ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
