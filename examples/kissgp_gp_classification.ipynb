{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "train_x = Variable(torch.linspace(0, 1, 26))\n",
    "train_y = Variable(torch.sign(torch.cos(train_x.data * (8 * math.pi))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from gpytorch.kernels import RBFKernel, GridInterpolationKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GPClassificationModel(gpytorch.GPModel):\n",
    "    def __init__(self):\n",
    "        super(GPClassificationModel,self).__init__(BernoulliLikelihood())\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-6, 6))\n",
    "        self.grid_covar_module = GridInterpolationKernel(self.covar_module)\n",
    "        self.register_parameter('log_outputscale', nn.Parameter(torch.Tensor([0])), bounds=(-6,6))\n",
    "        self.initialize_interpolation_grid(30)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.grid_covar_module(x)\n",
    "        covar_x = covar_x.mul(self.log_outputscale.exp())\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "\n",
    "prior_model = GPClassificationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_and_predictions(model, plot_train_data=True):\n",
    "    f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    test_x = Variable(torch.linspace(0, 1, 100))\n",
    "    observed_pred = model(test_x)\n",
    "\n",
    "    def ax_plot(ax, rand_var, title):\n",
    "        if plot_train_data:\n",
    "            ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "        pred_labels = rand_var.mean().ge(0.5).float().mul(2).sub(1)\n",
    "        ax.plot(test_x.data.numpy(), pred_labels.data.numpy(), 'b')\n",
    "        ax.set_ylim([-3, 3])\n",
    "        ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = plot_model_and_predictions(prior_model, plot_train_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gpytorch.inference import Inference\n",
    "infer = Inference(prior_model)\n",
    "posterior_model = infer.run(train_x, train_y)\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "posterior_model.train()\n",
    "optimizer = optim.Adam(posterior_model.parameters(), lr=0.1)\n",
    "optimizer.n_iter = 0\n",
    "for i in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    output = posterior_model.forward(train_x)\n",
    "    loss = -posterior_model.marginal_log_likelihood(output, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.n_iter += 1\n",
    "    print('Iter %d/20 - Loss: %.3f   log_lengthscale: %.3f' % (\n",
    "        i + 1, loss.data[0],\n",
    "        posterior_model.prior_model.covar_module.log_lengthscale.data.squeeze()[0],\n",
    "    ))\n",
    "    optimizer.step()\n",
    "    \n",
    "# Set back to eval mode\n",
    "posterior_model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = plot_model_and_predictions(posterior_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
