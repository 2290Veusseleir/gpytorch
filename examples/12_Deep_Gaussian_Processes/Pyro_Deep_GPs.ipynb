{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "from gpytorch.models.pyro_deep_gp import AbstractPyroHiddenGPLayer, AbstractPyroDeepGP\n",
    "from gpytorch.variational import VariationalStrategy, CholeskyVariationalDistribution\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel, RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INDUCING = 128\n",
    "\n",
    "\n",
    "class ToyHiddenGPLayer(AbstractPyroHiddenGPLayer):\n",
    "    def __init__(self, input_dims, output_dims, name=\"\"):\n",
    "        inducing_points = torch.randn(output_dims, NUM_INDUCING, input_dims)\n",
    "        \n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            num_inducing_points=inducing_points.size(-2),\n",
    "            batch_size=output_dims\n",
    "        )\n",
    "        \n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True\n",
    "        )\n",
    "        \n",
    "        super().__init__(variational_strategy, input_dims, output_dims, name)\n",
    "        \n",
    "        batch_shape = torch.Size([output_dims])\n",
    "        \n",
    "        self.mean_module = ConstantMean(batch_shape=batch_shape)\n",
    "        self.covar_module = ScaleKernel(\n",
    "            MaternKernel(nu=2.5, batch_shape=batch_shape, ard_num_dims=input_dims), \n",
    "            batch_shape=batch_shape\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Double inheritance\n",
    "class ToyDeepGP(AbstractPyroDeepGP):\n",
    "    def __init__(self, input_dims, output_dims, total_num_data, hidden_gp_layers, likelihood, name=\"\"):\n",
    "        inducing_points = torch.randn(output_dims, NUM_INDUCING, input_dims)\n",
    "        \n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            num_inducing_points=inducing_points.size(-2),\n",
    "            batch_size=output_dims\n",
    "        )\n",
    "        \n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True\n",
    "        )\n",
    "        \n",
    "        super().__init__(\n",
    "            variational_strategy,\n",
    "            input_dims,\n",
    "            output_dims,\n",
    "            total_num_data,\n",
    "            hidden_gp_layers,\n",
    "            likelihood,\n",
    "            name\n",
    "        )\n",
    "        \n",
    "        batch_shape = torch.Size([output_dims])\n",
    "        \n",
    "        self.mean_module = ConstantMean(batch_shape=batch_shape)\n",
    "        self.covar_module = ScaleKernel(\n",
    "            MaternKernel(nu=2.5, batch_shape=batch_shape, ard_num_dims=input_dims), \n",
    "            batch_shape=batch_shape\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os.path\n",
    "from scipy.io import loadmat\n",
    "from math import floor\n",
    "import numpy as np\n",
    "\n",
    "dataset_name = 'elevators'\n",
    "\n",
    "data = torch.Tensor(loadmat(f'/home/jake.gardner/data/{dataset_name}.mat')['data'])\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "N = data.shape[0]\n",
    "np.random.seed(0)\n",
    "data = data[np.random.permutation(np.arange(N)),:]\n",
    "\n",
    "train_n = int(floor(0.8*len(X)))\n",
    "\n",
    "train_x = X[:train_n, :].contiguous().cuda()\n",
    "train_y = y[:train_n].contiguous().cuda()\n",
    "\n",
    "test_x = X[train_n:, :].contiguous().cuda()\n",
    "test_y = y[train_n:].contiguous().cuda()\n",
    "\n",
    "mean = train_x.mean(dim=-2, keepdim=True)\n",
    "std = train_x.std(dim=-2, keepdim=True) + 1e-6\n",
    "train_x = (train_x - mean) / std\n",
    "test_x = (test_x - mean) / std\n",
    "\n",
    "mean,std = train_y.mean(),train_y.std()\n",
    "train_y = (train_y - mean) / std\n",
    "test_y = (test_y - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 13279, test data set: 3320, some float: 0.253\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data size: {train_x.size(-2)}, test data set: {test_x.size(-2)}, some float: {std:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToyDeepGP(\n",
       "  (variational_strategy): VariationalStrategy(\n",
       "    (variational_distribution): CholeskyVariationalDistribution()\n",
       "  )\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (quadrature): GaussHermiteQuadrature1D()\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (mean_module): ConstantMean()\n",
       "  (covar_module): ScaleKernel(\n",
       "    (base_kernel): MaternKernel(\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "    )\n",
       "    (raw_outputscale_constraint): Positive()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood = GaussianLikelihood()\n",
    "\n",
    "hidden_gp = ToyHiddenGPLayer(train_x.size(-1), 10, name=\"layer1\").cuda()\n",
    "deep_gp = ToyDeepGP(10, 1, train_x.size(-2), [hidden_gp], likelihood, name=\"output_layer\").cuda()\n",
    "\n",
    "hidden_gp.eval()\n",
    "deep_gp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('trained_gp.pth')\n",
    "deep_gp.load_state_dict(state_dict[0])\n",
    "hidden_gp.load_state_dict(state_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_gp.EXACT = False\n",
    "hidden_gp.EXACT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, [0 / 13], loss = 0.056, last epoch loss = 0.004\n",
      "Epoch 0, [1 / 13], loss = 0.055, last epoch loss = 0.009\n",
      "Epoch 0, [2 / 13], loss = 0.055, last epoch loss = 0.013\n",
      "Epoch 0, [3 / 13], loss = 0.055, last epoch loss = 0.017\n",
      "Epoch 0, [4 / 13], loss = 0.056, last epoch loss = 0.021\n",
      "Epoch 0, [5 / 13], loss = 0.055, last epoch loss = 0.026\n",
      "Epoch 0, [6 / 13], loss = 0.055, last epoch loss = 0.030\n",
      "Epoch 0, [7 / 13], loss = 0.056, last epoch loss = 0.034\n",
      "Epoch 0, [8 / 13], loss = 0.055, last epoch loss = 0.038\n",
      "Epoch 0, [9 / 13], loss = 0.055, last epoch loss = 0.043\n",
      "Epoch 0, [10 / 13], loss = 0.055, last epoch loss = 0.047\n",
      "Epoch 0, [11 / 13], loss = 0.056, last epoch loss = 0.051\n",
      "Epoch 0, [12 / 13], loss = 0.056, last epoch loss = 0.055\n",
      "Epoch 1, [0 / 13], loss = 0.057, last epoch loss = 0.004\n",
      "Epoch 1, [1 / 13], loss = 0.056, last epoch loss = 0.009\n",
      "Epoch 1, [2 / 13], loss = 0.055, last epoch loss = 0.013\n",
      "Epoch 1, [3 / 13], loss = 0.056, last epoch loss = 0.017\n",
      "Epoch 1, [4 / 13], loss = 0.055, last epoch loss = 0.021\n",
      "Epoch 1, [5 / 13], loss = 0.055, last epoch loss = 0.026\n",
      "Epoch 1, [6 / 13], loss = 0.055, last epoch loss = 0.030\n",
      "Epoch 1, [7 / 13], loss = 0.056, last epoch loss = 0.034\n",
      "Epoch 1, [8 / 13], loss = 0.055, last epoch loss = 0.039\n",
      "Epoch 1, [9 / 13], loss = 0.055, last epoch loss = 0.043\n",
      "Epoch 1, [10 / 13], loss = 0.055, last epoch loss = 0.047\n",
      "Epoch 1, [11 / 13], loss = 0.056, last epoch loss = 0.051\n",
      "Epoch 1, [12 / 13], loss = 0.055, last epoch loss = 0.056\n",
      "Epoch 2, [0 / 13], loss = 0.055, last epoch loss = 0.004\n",
      "Epoch 2, [1 / 13], loss = 0.056, last epoch loss = 0.009\n",
      "Epoch 2, [2 / 13], loss = 0.056, last epoch loss = 0.013\n",
      "Epoch 2, [3 / 13], loss = 0.056, last epoch loss = 0.017\n",
      "Epoch 2, [4 / 13], loss = 0.056, last epoch loss = 0.021\n",
      "Epoch 2, [5 / 13], loss = 0.055, last epoch loss = 0.026\n",
      "Epoch 2, [6 / 13], loss = 0.055, last epoch loss = 0.030\n",
      "Epoch 2, [7 / 13], loss = 0.056, last epoch loss = 0.034\n",
      "Epoch 2, [8 / 13], loss = 0.056, last epoch loss = 0.039\n",
      "Epoch 2, [9 / 13], loss = 0.056, last epoch loss = 0.043\n",
      "Epoch 2, [10 / 13], loss = 0.056, last epoch loss = 0.047\n",
      "Epoch 2, [11 / 13], loss = 0.056, last epoch loss = 0.051\n",
      "Epoch 2, [12 / 13], loss = 0.055, last epoch loss = 0.056\n",
      "Epoch 3, [0 / 13], loss = 0.056, last epoch loss = 0.004\n",
      "Epoch 3, [1 / 13], loss = 0.056, last epoch loss = 0.009\n",
      "Epoch 3, [2 / 13], loss = 0.056, last epoch loss = 0.013\n",
      "Epoch 3, [3 / 13], loss = 0.055, last epoch loss = 0.017\n",
      "Epoch 3, [4 / 13], loss = 0.056, last epoch loss = 0.021\n",
      "Epoch 3, [5 / 13], loss = 0.055, last epoch loss = 0.026\n",
      "Epoch 3, [6 / 13], loss = 0.056, last epoch loss = 0.030\n",
      "Epoch 3, [7 / 13], loss = 0.056, last epoch loss = 0.034\n",
      "Epoch 3, [8 / 13], loss = 0.056, last epoch loss = 0.039\n",
      "Epoch 3, [9 / 13], loss = 0.055, last epoch loss = 0.043\n",
      "Epoch 3, [10 / 13], loss = 0.055, last epoch loss = 0.047\n",
      "Epoch 3, [11 / 13], loss = 0.055, last epoch loss = 0.051\n",
      "Epoch 3, [12 / 13], loss = 0.056, last epoch loss = 0.056\n",
      "Epoch 4, [0 / 13], loss = 0.056, last epoch loss = 0.004\n",
      "Epoch 4, [1 / 13], loss = 0.056, last epoch loss = 0.009\n",
      "Epoch 4, [2 / 13], loss = 0.055, last epoch loss = 0.013\n",
      "Epoch 4, [3 / 13], loss = 0.056, last epoch loss = 0.017\n",
      "Epoch 4, [4 / 13], loss = 0.055, last epoch loss = 0.021\n",
      "Epoch 4, [5 / 13], loss = 0.055, last epoch loss = 0.026\n",
      "Epoch 4, [6 / 13], loss = 0.056, last epoch loss = 0.030\n",
      "Epoch 4, [7 / 13], loss = 0.056, last epoch loss = 0.034\n",
      "Epoch 4, [8 / 13], loss = 0.056, last epoch loss = 0.038\n",
      "Epoch 4, [9 / 13], loss = 0.055, last epoch loss = 0.043\n",
      "Epoch 4, [10 / 13], loss = 0.056, last epoch loss = 0.047\n",
      "Epoch 4, [11 / 13], loss = 0.056, last epoch loss = 0.051\n",
      "Epoch 4, [12 / 13], loss = 0.055, last epoch loss = 0.056\n",
      "Epoch 5, [0 / 13], loss = 0.055, last epoch loss = 0.004\n",
      "Epoch 5, [1 / 13], loss = 0.055, last epoch loss = 0.009\n",
      "Epoch 5, [2 / 13], loss = 0.056, last epoch loss = 0.013\n",
      "Epoch 5, [3 / 13], loss = 0.056, last epoch loss = 0.017\n",
      "Epoch 5, [4 / 13], loss = 0.056, last epoch loss = 0.021\n",
      "Epoch 5, [5 / 13], loss = 0.055, last epoch loss = 0.026\n",
      "Epoch 5, [6 / 13], loss = 0.055, last epoch loss = 0.030\n",
      "Epoch 5, [7 / 13], loss = 0.056, last epoch loss = 0.034\n",
      "Epoch 5, [8 / 13], loss = 0.056, last epoch loss = 0.039\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7d3315fb5ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mminibatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg_fmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg_fmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyro.infer import SVI, TraceMeanField_ELBO, Trace_ELBO\n",
    "\n",
    "from pyro import optim\n",
    "\n",
    "optimizer = optim.Adam({\"lr\": 0.0, \"betas\": (0.96, 0.999)})\n",
    "\n",
    "\n",
    "elbo = Trace_ELBO(num_particles=64, vectorize_particles=True, max_plate_nesting=1)\n",
    "svi = SVI(deep_gp.model, deep_gp.guide, optimizer, elbo)\n",
    "\n",
    "for epoch_i in range(30):\n",
    "    epoch_loss = 0\n",
    "    for minibatch_i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        loss = svi.step(x_batch, y_batch)\n",
    "        epoch_loss = epoch_loss + loss / len(train_loader)\n",
    "        if minibatch_i % 1 == 0:\n",
    "            print(f'Epoch {epoch_i}, [{minibatch_i} / {len(train_loader)}], loss = {loss:.3f}, last epoch loss = {epoch_loss:.3f}')\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.99996286221203\n"
     ]
    }
   ],
   "source": [
    "x=41602.5156+5616.2090\n",
    "y=737.793\n",
    "print(x/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model site _INPUT\n",
      "model site output_layer.gp_layer$$$variational_strategy.inducing_points\n",
      "model site output_layer.gp_layer$$$variational_strategy.variational_distribution.variational_mean\n",
      "model site output_layer.gp_layer$$$variational_strategy.variational_distribution.chol_variational_covar\n",
      "model site output_layer.gp_layer$$$likelihood.noise_covar.raw_noise\n",
      "model site output_layer.gp_layer$$$mean_module.constant\n",
      "model site output_layer.gp_layer$$$covar_module.raw_outputscale\n",
      "model site output_layer.gp_layer$$$covar_module.base_kernel.raw_lengthscale\n",
      "model site layer1.gp_layer$$$variational_strategy.inducing_points\n",
      "model site layer1.gp_layer$$$variational_strategy.variational_distribution.variational_mean\n",
      "model site layer1.gp_layer$$$variational_strategy.variational_distribution.chol_variational_covar\n",
      "model site layer1.gp_layer$$$mean_module.constant\n",
      "model site layer1.gp_layer$$$covar_module.raw_outputscale\n",
      "model site layer1.gp_layer$$$covar_module.base_kernel.raw_lengthscale\n",
      "model site layer1.inducing_values\n",
      "model site output_layer.inducing_values\n",
      "model site output_layer.data_plate\n",
      "model site output_layer.output_value\n",
      "model site _RETURN\n",
      "guide site _INPUT\n",
      "guide site layer1.inducing_values\n",
      "guide site output_layer.inducing_values\n",
      "guide site _RETURN\n"
     ]
    }
   ],
   "source": [
    "from pyro.poutine import trace, replay\n",
    "\n",
    "guide_trace = trace(deep_gp.guide).get_trace(x_batch, y_batch)\n",
    "\n",
    "model_trace = trace(replay(deep_gp.model, guide_trace)).get_trace(x_batch, y_batch)\n",
    "\n",
    "for site in model_trace:\n",
    "    print(\"model site\", site)\n",
    "for site in guide_trace:\n",
    "    print(\"guide site\", site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model site _INPUT\n",
      "model site output_layer.gp_layer$$$variational_strategy.inducing_points\n",
      "model site output_layer.gp_layer$$$variational_strategy.variational_distribution.variational_mean\n",
      "model site output_layer.gp_layer$$$variational_strategy.variational_distribution.chol_variational_covar\n",
      "model site output_layer.gp_layer$$$likelihood.noise_covar.raw_noise\n",
      "model site output_layer.gp_layer$$$mean_module.constant\n",
      "model site output_layer.gp_layer$$$covar_module.raw_outputscale\n",
      "model site output_layer.gp_layer$$$covar_module.base_kernel.raw_lengthscale\n",
      "model site layer1.gp_layer$$$variational_strategy.inducing_points\n",
      "model site layer1.gp_layer$$$variational_strategy.variational_distribution.variational_mean\n",
      "model site layer1.gp_layer$$$variational_strategy.variational_distribution.chol_variational_covar\n",
      "model site layer1.gp_layer$$$mean_module.constant\n",
      "model site layer1.gp_layer$$$covar_module.raw_outputscale\n",
      "model site layer1.gp_layer$$$covar_module.base_kernel.raw_lengthscale\n",
      "model site layer1.inducing_values\n",
      "model site output_layer.inducing_values\n",
      "model site output_layer.data_plate\n",
      "model site output_layer.output_value\n",
      "model site _RETURN\n",
      "guide site _INPUT\n",
      "guide site layer1.inducing_values\n",
      "guide site output_layer.inducing_values\n",
      "guide site _RETURN\n"
     ]
    }
   ],
   "source": [
    "deep_gp.EXACT = True\n",
    "hidden_gp.EXACT = True\n",
    "\n",
    "guide_trace = trace(deep_gp.guide).get_trace(x_batch, y_batch)\n",
    "\n",
    "good_model_trace = trace(replay(deep_gp.model, guide_trace)).get_trace(x_batch, y_batch)\n",
    "\n",
    "for site in good_model_trace:\n",
    "    print(\"model site\", site)\n",
    "for site in guide_trace:\n",
    "    print(\"guide site\", site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.7838e-12, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#print(model_trace.nodes['layer1.inducing_values']['value'].shape)\n",
    "good_model_trace.compute_log_prob()\n",
    "print(512*good_model_trace.nodes['output_layer.output_value']['log_prob'].mean())\n",
    "#print(guide_trace.nodes['layer1.inducing_values']['value'].shape)\n",
    "#print(guide_trace.nodes['output_layer.inducing_values']['value'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.8091e-12, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#print(model_trace.nodes['layer1.inducing_values']['value'].shape)\n",
    "model_trace.compute_log_prob()\n",
    "print((512*model_trace.nodes['output_layer.output_value']['log_prob']).mean())\n",
    "#print(guide_trace.nodes['layer1.inducing_values']['value'].shape)\n",
    "#print(guide_trace.nodes['output_layer.inducing_values']['value'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0734,  0.0050, -0.0023,  ...,  0.0046,  0.0047,  0.0040],\n",
       "        [ 0.0050,  0.0494, -0.0011,  ...,  0.0014, -0.0038,  0.0036],\n",
       "        [-0.0023, -0.0011,  0.0538,  ..., -0.0032, -0.0021, -0.0057],\n",
       "        ...,\n",
       "        [ 0.0046,  0.0014, -0.0032,  ...,  0.0954, -0.0039, -0.0008],\n",
       "        [ 0.0047, -0.0038, -0.0021,  ..., -0.0039,  0.0929,  0.0027],\n",
       "        [ 0.0040,  0.0036, -0.0057,  ..., -0.0008,  0.0027,  0.0656]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_gp.variational_distribution.covariance_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7938, -0.1091, -0.8158,  ...,  0.3406, -2.0006,  1.1564],\n",
       "        [ 0.2544, -0.2884, -0.8945,  ...,  0.9977, -0.5145,  1.2859],\n",
       "        [ 0.5308,  0.1070,  0.8624,  ...,  1.1606,  0.9395,  0.2596],\n",
       "        ...,\n",
       "        [-0.1504,  0.0851, -1.1425,  ...,  0.3579,  0.2761,  1.4231],\n",
       "        [ 0.0246, -1.6314, -0.5040,  ..., -1.0291, -1.5203,  0.1858],\n",
       "        [-1.1408, -0.9031, -0.9281,  ..., -0.3486, -0.7034,  0.9233]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(samples).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetmean = torch.cat(samples).mean(0)\n",
    "targetstd = torch.cat(samples).std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5476316213607788,\n",
       " 0.5202265381813049,\n",
       " 0.6973344683647156,\n",
       " 0.5178024172782898,\n",
       " 0.6270923614501953,\n",
       " 0.6165500283241272,\n",
       " 0.6566213965415955,\n",
       " 0.6366702318191528,\n",
       " 0.6930236220359802,\n",
       " 0.5574667453765869]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_gp.variational_strategy(deep_gp.debug_inputs).variance.sqrt().squeeze()[:10].data.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5367881655693054,\n",
       " 0.5097756385803223,\n",
       " 0.6767644286155701,\n",
       " 0.5547028183937073,\n",
       " 0.6438401341438293,\n",
       " 0.600436270236969,\n",
       " 0.6482633948326111,\n",
       " 0.6319460272789001,\n",
       " 0.7010195851325989,\n",
       " 0.5514597296714783]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetstd.squeeze()[:10].data.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4946]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_gp.mean_module.constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples2 = []\n",
    "for i in range(500):\n",
    "    with torch.no_grad():\n",
    "        sample = ToyHiddenGPLayer.model(deep_gp, inputs[0], return_samples=True)\n",
    "        samples2.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0006227144040167332"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_gp.variational_strategy(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3868, -0.5244,  0.2853,  ..., -1.2279, -0.3916, -0.5635],\n",
       "        [-0.0413, -0.1444, -0.0837,  ..., -0.0363, -0.0189,  0.0718],\n",
       "        [-0.0035, -0.0599,  0.0911,  ...,  0.1380,  0.3721,  0.4495],\n",
       "        ...,\n",
       "        [ 0.0637, -0.3526, -0.0740,  ..., -0.0193, -0.0448,  0.0386],\n",
       "        [-0.2438, -0.2021,  0.0399,  ..., -0.0111, -0.1915, -0.1610],\n",
       "        [-1.3683, -1.5571,  0.9494,  ...,  0.8288, -0.7905, -0.8687]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_gp.variational_strategy.variational_distribution.variational_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save([deep_gp.state_dict(), hidden_gp.state_dict()], 'trained_gp.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('variational_strategy.inducing_points',\n",
       "               tensor([[[ 0.2636, -0.3732,  0.3966,  ..., -0.0683, -0.3187,  0.2445],\n",
       "                        [-0.9679,  0.1655,  0.2087,  ...,  0.0339, -0.2558,  0.1049],\n",
       "                        [-0.4833,  0.6904,  0.4577,  ...,  0.2560,  0.5616,  0.4499],\n",
       "                        ...,\n",
       "                        [-0.6785,  0.1705, -0.3937,  ...,  0.7312,  0.9520,  0.4070],\n",
       "                        [ 1.2968,  1.3922, -0.0182,  ...,  0.4934, -1.0872,  2.0364],\n",
       "                        [-0.4223, -0.1983, -0.2489,  ...,  0.0747,  0.8132, -1.8235]]],\n",
       "                      device='cuda:0')),\n",
       "              ('variational_strategy.variational_params_initialized',\n",
       "               tensor(1, device='cuda:0')),\n",
       "              ('variational_strategy.variational_distribution.variational_mean',\n",
       "               tensor([[ 1.3314,  0.7089,  1.9481, -0.3457,  0.6118,  1.9193,  1.8307, -0.3567,\n",
       "                        -0.2294,  1.1335,  0.2448, -0.6334,  1.3863,  0.2186,  0.3395, -0.3495,\n",
       "                         0.6920,  1.7544,  2.5838,  0.2797, -0.6646, -0.2349, -0.8339,  1.4991,\n",
       "                         0.2717, -0.7130,  0.7957,  1.6956, -0.3286, -0.9367, -1.0112, -0.0139,\n",
       "                         0.3128,  1.6241,  1.0971,  1.5493,  0.4092,  0.6126,  1.6606,  1.1931,\n",
       "                         0.6454, -0.6631, -0.6110,  1.1175,  2.1498, -1.2715, -0.6385, -0.6772,\n",
       "                         1.4255, -0.7034,  0.6117,  0.1494,  2.5168,  0.6957, -0.3820,  1.5426,\n",
       "                        -0.3654,  0.3731, -1.2612, -0.3730,  1.1771, -0.5116, -0.7764,  0.3096,\n",
       "                        -0.1260,  2.2032,  0.4629,  0.5653, -0.2382, -0.2364, -0.9739,  1.1094,\n",
       "                        -0.3716, -0.2424, -0.4352,  1.6289, -0.8833,  2.2889,  0.6132,  1.7173,\n",
       "                        -0.8371,  2.5240,  0.9607,  2.4373,  0.7456,  0.1131,  0.5785,  2.5406,\n",
       "                         0.1681,  0.3541,  0.0209,  0.1446,  1.6225,  0.2875,  0.4460,  0.4943,\n",
       "                         2.6687, -0.4571,  0.0634, -0.6419,  1.2770, -0.0785, -0.3816, -0.5443,\n",
       "                         0.1467, -1.0238, -0.5116,  0.4532,  0.5097,  2.6153,  0.2383,  0.7494,\n",
       "                         1.0353, -0.7379, -1.4218, -0.3537,  1.8488, -0.6282,  1.5714, -0.8697,\n",
       "                        -1.2237,  1.2112,  2.4319,  0.8747,  0.5752,  1.0936,  1.8036, -0.7086]],\n",
       "                      device='cuda:0')),\n",
       "              ('variational_strategy.variational_distribution.chol_variational_covar',\n",
       "               tensor([[[ 5.5080e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [ 2.0723e-01,  1.2862e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [ 6.0920e-02,  2.7033e-01,  1.0475e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        ...,\n",
       "                        [ 3.6041e-01,  4.5408e-01,  5.1203e-01,  ...,  8.7649e-01,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [-9.5459e-02, -1.7046e-02,  5.6685e-02,  ...,  2.7151e-02,\n",
       "                          8.8209e-01,  0.0000e+00],\n",
       "                        [-2.8053e-02, -4.4413e-02,  2.9693e-02,  ...,  6.6604e-03,\n",
       "                         -5.1907e-04,  4.9982e-01]]], device='cuda:0')),\n",
       "              ('likelihood.noise_covar.raw_noise',\n",
       "               tensor([0.], device='cuda:0')),\n",
       "              ('mean_module.constant', tensor([[-0.4946]], device='cuda:0')),\n",
       "              ('covar_module.raw_outputscale',\n",
       "               tensor([0.0432], device='cuda:0')),\n",
       "              ('covar_module.base_kernel.raw_lengthscale',\n",
       "               tensor([[[1.2852, 1.2088, 1.2645, 1.4368, 1.0877, 1.2092, 1.2188, 1.3604,\n",
       "                         1.2681, 0.3593]]], device='cuda:0'))]),\n",
       " OrderedDict([('variational_strategy.inducing_points',\n",
       "               tensor([[[-2.0406e+00,  1.6009e+00,  2.6213e-01,  ...,  1.5476e-01,\n",
       "                          6.5024e-01,  5.8085e-01],\n",
       "                        [ 3.6869e-01, -2.4003e+00, -1.0299e+00,  ...,  5.3718e-01,\n",
       "                          4.6068e-01,  7.7863e-01],\n",
       "                        [ 8.6998e-01,  2.2579e+00, -4.7252e-01,  ..., -1.5602e-01,\n",
       "                         -1.9515e-01,  5.0530e-01],\n",
       "                        ...,\n",
       "                        [-2.6968e+00, -5.4716e-01,  7.9153e-01,  ...,  2.1210e+00,\n",
       "                         -3.9698e-02,  1.9038e-03],\n",
       "                        [-1.5389e-01, -2.5327e-01,  3.0994e-01,  ..., -1.3016e+00,\n",
       "                         -1.2204e-02,  3.3077e+00],\n",
       "                        [-3.7597e-01, -2.4269e+00, -7.1852e-01,  ..., -1.4106e+00,\n",
       "                          4.7785e-01,  3.6868e-01]],\n",
       "               \n",
       "                       [[-6.3363e-01,  5.1305e-01, -1.7139e+00,  ..., -1.6861e+00,\n",
       "                          9.2876e-01,  2.1989e-01],\n",
       "                        [ 2.0309e+00,  9.9524e-02,  1.1101e+00,  ...,  6.5032e-02,\n",
       "                          1.9796e-02,  7.7553e-02],\n",
       "                        [-4.5165e-01,  2.5894e-01,  7.5887e-01,  ..., -1.6424e-01,\n",
       "                          2.0460e+00,  1.1084e+00],\n",
       "                        ...,\n",
       "                        [-8.5942e-01,  2.8562e-01,  7.6325e-01,  ..., -4.2974e-02,\n",
       "                         -7.7751e-01, -3.2896e-01],\n",
       "                        [-2.5361e-01, -1.1441e+00, -1.8156e+00,  ...,  3.8099e-01,\n",
       "                         -5.4269e-02, -3.6153e-01],\n",
       "                        [ 4.3035e-01,  3.9192e-02,  5.9940e-02,  ..., -1.4203e+00,\n",
       "                          1.0224e+00, -1.4400e+00]],\n",
       "               \n",
       "                       [[-1.9497e+00, -8.5260e-02,  9.4645e-01,  ...,  3.0835e-01,\n",
       "                          5.9267e-01,  7.8885e-01],\n",
       "                        [-9.5938e-02,  4.0386e-01, -1.6062e+00,  ...,  2.2234e+00,\n",
       "                          2.1220e+00,  2.2938e-01],\n",
       "                        [-7.8168e-01,  5.2538e-01, -1.3864e-01,  ...,  1.2639e+00,\n",
       "                          2.1127e-01,  6.8695e-01],\n",
       "                        ...,\n",
       "                        [ 2.9024e-01, -2.7849e-01, -4.6398e-01,  ...,  6.9271e-01,\n",
       "                         -5.2421e-02,  2.6638e-01],\n",
       "                        [-1.8002e-03,  1.1574e-01, -4.7118e-02,  ..., -7.9750e-01,\n",
       "                         -1.4472e-01, -4.2122e-01],\n",
       "                        [ 2.7978e-02, -4.0131e-01,  1.0940e+00,  ...,  4.0392e-01,\n",
       "                          9.4784e-01,  4.2077e-01]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[-3.3771e-01, -8.1567e-02,  1.1673e+00,  ..., -2.0180e-01,\n",
       "                          1.1483e-02,  1.5062e+00],\n",
       "                        [ 1.9875e-01, -8.6616e-01, -5.3195e-01,  ...,  4.6693e-02,\n",
       "                          1.2367e-02, -4.8830e-01],\n",
       "                        [-4.3678e-01, -1.9470e+00,  3.7059e-01,  ..., -1.0617e+00,\n",
       "                          3.5910e-01, -2.8515e-01],\n",
       "                        ...,\n",
       "                        [ 2.0571e-01,  3.1166e-01,  1.2402e+00,  ...,  1.9734e+00,\n",
       "                          1.1752e+00, -1.1535e+00],\n",
       "                        [ 4.0348e-01,  4.7093e-01, -4.4620e-01,  ..., -1.1187e+00,\n",
       "                         -2.5832e-01,  3.3242e-01],\n",
       "                        [-5.0726e-01,  2.0589e+00,  9.1070e-02,  ...,  1.6260e-01,\n",
       "                         -1.4003e-01,  1.1081e+00]],\n",
       "               \n",
       "                       [[ 5.2346e-01, -2.0343e-01, -2.1456e-01,  ...,  4.3500e-01,\n",
       "                          9.3976e-02,  1.7981e+00],\n",
       "                        [-9.7124e-01, -2.7895e-01, -1.0190e+00,  ..., -4.1283e-02,\n",
       "                         -1.8998e-01,  1.1089e+00],\n",
       "                        [-8.8176e-01, -2.9320e-01,  6.6468e-01,  ...,  1.0781e-01,\n",
       "                          2.3573e+00, -1.5629e+00],\n",
       "                        ...,\n",
       "                        [ 1.4181e+00, -5.3443e-01, -4.5016e-01,  ...,  7.1829e-01,\n",
       "                         -3.0784e-01, -1.7094e+00],\n",
       "                        [-4.5023e-01, -1.1048e+00,  9.0331e-01,  ..., -5.9867e-01,\n",
       "                          6.1846e-02, -6.4591e-01],\n",
       "                        [ 1.5833e+00,  2.7875e-01,  1.3153e-01,  ..., -1.5077e-01,\n",
       "                          1.2261e-01,  1.6802e+00]],\n",
       "               \n",
       "                       [[ 2.3931e+00, -5.5647e-01,  1.2047e+00,  ..., -3.7297e-01,\n",
       "                         -5.6133e-02,  1.7249e+00],\n",
       "                        [-8.3190e-01,  7.8497e-01,  1.7236e+00,  ...,  1.8656e+00,\n",
       "                         -1.4294e+00, -7.0753e-02],\n",
       "                        [ 6.4152e-02, -7.8805e-01,  8.1315e-01,  ..., -7.2477e-02,\n",
       "                         -2.6248e-01, -4.4670e-01],\n",
       "                        ...,\n",
       "                        [ 7.7093e-02,  7.7768e-01, -1.0776e+00,  ...,  1.6959e+00,\n",
       "                         -1.4185e+00, -3.6294e-02],\n",
       "                        [ 5.0592e-01, -1.1011e+00,  2.0339e+00,  ..., -3.8176e-01,\n",
       "                         -3.6090e-01, -4.1579e-01],\n",
       "                        [ 3.2500e-01, -6.6610e-01, -2.4372e+00,  ...,  3.1175e+00,\n",
       "                         -3.4450e-01, -1.5599e+00]]], device='cuda:0')),\n",
       "              ('variational_strategy.variational_params_initialized',\n",
       "               tensor(1, device='cuda:0')),\n",
       "              ('variational_strategy.variational_distribution.variational_mean',\n",
       "               tensor([[-0.3868, -0.5244,  0.2853,  ..., -1.2279, -0.3916, -0.5635],\n",
       "                       [-0.0413, -0.1444, -0.0837,  ..., -0.0363, -0.0189,  0.0718],\n",
       "                       [-0.0035, -0.0599,  0.0911,  ...,  0.1380,  0.3721,  0.4495],\n",
       "                       ...,\n",
       "                       [ 0.0637, -0.3526, -0.0740,  ..., -0.0193, -0.0448,  0.0386],\n",
       "                       [-0.2438, -0.2021,  0.0399,  ..., -0.0111, -0.1915, -0.1610],\n",
       "                       [-1.3683, -1.5571,  0.9494,  ...,  0.8288, -0.7905, -0.8687]],\n",
       "                      device='cuda:0')),\n",
       "              ('variational_strategy.variational_distribution.chol_variational_covar',\n",
       "               tensor([[[ 2.7096e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [ 1.8305e-02,  2.2159e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [-8.6182e-03, -4.0479e-03,  2.3174e-01,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        ...,\n",
       "                        [ 1.6869e-02,  4.9981e-03, -1.3193e-02,  ...,  2.6683e-01,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [ 1.7521e-02, -1.8390e-02, -8.8729e-03,  ...,  6.9766e-03,\n",
       "                          2.5336e-01,  0.0000e+00],\n",
       "                        [ 1.4765e-02,  1.5052e-02, -2.3760e-02,  ..., -4.5551e-03,\n",
       "                         -8.9663e-04,  2.0977e-01]],\n",
       "               \n",
       "                       [[ 3.7849e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [ 3.3312e-02,  2.5850e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [ 2.1080e-02,  1.0489e-02,  3.7651e-01,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        ...,\n",
       "                        [-1.0960e-02,  1.7447e-02, -1.4708e-02,  ...,  3.6063e-01,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [ 1.7052e-02,  1.5811e-02, -1.0675e-02,  ..., -6.6706e-03,\n",
       "                          2.9474e-01,  0.0000e+00],\n",
       "                        [ 3.1822e-02,  6.9633e-03,  1.2621e-02,  ..., -3.5908e-03,\n",
       "                          4.7332e-04,  3.4027e-01]],\n",
       "               \n",
       "                       [[ 3.6633e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [-1.1426e-03,  3.5150e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [-4.6903e-03,  3.8059e-03,  3.5188e-01,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        ...,\n",
       "                        [-1.8786e-03, -3.3941e-03,  9.6413e-03,  ...,  2.6452e-01,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [-1.0912e-02,  9.6282e-03,  4.3563e-03,  ..., -7.6724e-03,\n",
       "                          2.7520e-01,  0.0000e+00],\n",
       "                        [-1.1515e-03, -7.1534e-04,  1.1756e-02,  ..., -5.5745e-03,\n",
       "                         -1.0709e-02,  2.8088e-01]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 3.7943e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [-1.7760e-02,  2.9589e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [-2.8337e-04, -4.5756e-04,  3.6834e-01,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        ...,\n",
       "                        [ 3.1733e-03, -3.6044e-03,  4.3474e-04,  ...,  3.6671e-01,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [ 1.5556e-02, -1.0749e-02,  5.3999e-03,  ..., -9.2792e-04,\n",
       "                          3.4707e-01,  0.0000e+00],\n",
       "                        [-4.7237e-03, -3.5958e-03,  1.5229e-03,  ..., -1.7006e-04,\n",
       "                          4.6427e-04,  3.2881e-01]],\n",
       "               \n",
       "                       [[ 3.3983e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [ 6.9171e-03,  2.5124e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [-1.2992e-03, -8.8413e-03,  3.9939e-01,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        ...,\n",
       "                        [-1.1573e-02, -9.1325e-03,  9.3940e-03,  ...,  3.4938e-01,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [-1.0027e-02,  2.3621e-02, -4.6846e-03,  ...,  1.2117e-03,\n",
       "                          2.9694e-01,  0.0000e+00],\n",
       "                        [ 1.9524e-02, -1.0781e-02,  3.7898e-03,  ..., -1.6048e-02,\n",
       "                         -3.7925e-03,  3.6594e-01]],\n",
       "               \n",
       "                       [[ 2.0587e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [ 1.8720e-02,  2.2858e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [-3.3657e-02, -4.9261e-03,  1.5237e-01,  ...,  0.0000e+00,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        ...,\n",
       "                        [-3.4850e-02,  1.8056e-02,  1.7943e-02,  ...,  1.8107e-01,\n",
       "                          0.0000e+00,  0.0000e+00],\n",
       "                        [-5.8174e-03,  1.6923e-02, -4.5754e-03,  ..., -1.0157e-02,\n",
       "                          2.0530e-01,  0.0000e+00],\n",
       "                        [ 1.3170e-03,  2.5708e-03,  1.3890e-03,  ..., -7.0359e-03,\n",
       "                         -1.0264e-03,  2.3353e-01]]], device='cuda:0')),\n",
       "              ('mean_module.constant', tensor([[-0.5735],\n",
       "                       [-0.0828],\n",
       "                       [-0.1030],\n",
       "                       [-0.0077],\n",
       "                       [-0.5017],\n",
       "                       [-0.0912],\n",
       "                       [ 0.0663],\n",
       "                       [-0.0161],\n",
       "                       [ 0.0879],\n",
       "                       [ 0.1513]], device='cuda:0')),\n",
       "              ('covar_module.raw_outputscale',\n",
       "               tensor([-2.2587, -1.8449, -1.9327, -1.9569, -2.1468, -1.8326, -1.8516, -1.9362,\n",
       "                       -1.7594, -2.3419], device='cuda:0')),\n",
       "              ('covar_module.base_kernel.raw_lengthscale',\n",
       "               tensor([[[ 2.4366,  3.9555,  3.5144,  3.5268,  3.9698,  3.0621,  3.0726,\n",
       "                          2.3951,  4.3277,  3.0285,  3.1154,  2.8773,  2.8050,  3.4490,\n",
       "                          2.8359,  4.2270,  3.0007,  3.0043]],\n",
       "               \n",
       "                       [[ 1.8996,  2.3507,  2.5230,  2.3244,  2.6201,  1.4776,  2.6552,\n",
       "                          2.2900,  2.1544,  2.2534,  2.3226,  2.3441,  2.3915,  2.4317,\n",
       "                          2.3168,  1.7573,  2.1502,  2.2460]],\n",
       "               \n",
       "                       [[ 1.1205,  2.3124,  2.2099,  2.1700,  2.1341,  1.9621,  2.0873,\n",
       "                          1.8672,  2.0177,  2.5910,  2.6408,  2.5194,  2.3631,  1.9093,\n",
       "                          2.2646,  1.4593,  2.2021,  2.6228]],\n",
       "               \n",
       "                       [[ 0.4026,  0.1599,  0.6054,  0.2678, -0.0095,  0.1697,  0.3437,\n",
       "                          0.3798,  0.4900,  0.1248,  0.1025,  0.3204,  0.2681,  0.3542,\n",
       "                          0.4338,  0.2240,  0.4786,  0.0701]],\n",
       "               \n",
       "                       [[ 3.0033,  3.1887,  2.9168,  3.3200,  3.2963,  2.2576,  3.2496,\n",
       "                          1.7618,  3.5091,  2.6800,  2.7980,  2.7016,  2.5850,  3.6768,\n",
       "                          2.4631,  3.4884,  2.7286,  2.5943]],\n",
       "               \n",
       "                       [[ 1.6607,  1.8862,  2.1058,  1.7828,  1.9895,  1.4391,  1.9889,\n",
       "                          1.4159,  1.8133,  1.2877,  1.5458,  1.1725,  1.3101,  1.5612,\n",
       "                          1.4839,  1.8308,  1.7045,  1.4617]],\n",
       "               \n",
       "                       [[ 2.8034,  3.2760,  2.8620,  2.5082,  3.4295,  1.5901,  2.9539,\n",
       "                          1.5776,  3.2928,  2.4990,  2.4416,  2.6885,  1.9320,  3.3660,\n",
       "                          2.8967,  3.4480,  2.7294,  1.9435]],\n",
       "               \n",
       "                       [[ 1.3970,  1.0169,  1.6583,  0.9777,  1.4741,  1.2047,  1.4222,\n",
       "                          1.5194,  1.3855,  1.4227,  1.2774,  1.4984,  1.4118,  0.7731,\n",
       "                          1.3246,  0.2013,  0.7639,  1.3781]],\n",
       "               \n",
       "                       [[ 1.5404,  2.7094,  2.6709,  2.4054,  2.8511,  2.2916,  2.3240,\n",
       "                          2.2081,  2.5859,  2.9573,  2.6405,  2.7079,  2.8740,  2.3703,\n",
       "                          2.0747,  2.2581,  2.3139,  2.8424]],\n",
       "               \n",
       "                       [[ 3.9293,  4.1510,  3.7889,  4.0416,  4.0753,  2.0236,  3.9073,\n",
       "                          2.2370,  4.2614,  3.1248,  3.4935,  3.3344,  3.4465,  4.4652,\n",
       "                          2.7498,  4.4260,  2.9110,  3.1081]]], device='cuda:0'))])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
