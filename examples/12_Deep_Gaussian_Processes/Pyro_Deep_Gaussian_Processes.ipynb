{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Gaussian Processes with Doubly Stochastic VI\n",
    "\n",
    "In this notebook, we provide a GPyTorch implementation of deep Gaussian processes, where training and inference is performed using the method of Salimbeni et al., 2017 (https://arxiv.org/abs/1705.08933) adapted to CG-based inference.\n",
    "\n",
    "We'll be training a simple two layer deep GP on the `elevators` UCI dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fire\n",
    "import math\n",
    "import time\n",
    "import pyro\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import namedtuple\n",
    "import gpytorch\n",
    "from gpytorch.models import AbstractVariationalGP, PyroVariationalGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy, WhitenedVariationalStrategy\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bayesian_benchmarks import data as _datasets\n",
    "\n",
    "try:\n",
    "    from gpytorch.variational import CholeskyVariationalStrategy, WhitenedCholeskyVariationalStrategy\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "For this example notebook, we'll be using the `elevators` UCI dataset used in the paper. Running the next cell downloads a copy of the dataset that has already been scaled and normalized appropriately. For this notebook, we'll simply be splitting the data using the first 80% of the data as training and the last 20% as testing.\n",
    "\n",
    "**Note**: Running the next cell will attempt to download a ~400 KB dataset file to the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os.path\n",
    "from scipy.io import loadmat\n",
    "from math import floor\n",
    "import numpy as np\n",
    "\n",
    "if not os.path.isfile('elevators.mat'):\n",
    "    print('Downloading \\'elevators\\' UCI dataset...')\n",
    "    urllib.request.urlretrieve('https://drive.google.com/uc?export=download&id=1jhWL3YUHvXIaftia4qeAyDwVxo6j1alk', 'elevators.mat')\n",
    "    \n",
    "data = torch.Tensor(loadmat('elevators.mat')['data'])\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "N = data.shape[0]\n",
    "np.random.seed(0)\n",
    "data = data[np.random.permutation(np.arange(N)),:]\n",
    "\n",
    "train_n = int(floor(0.8*len(X)))\n",
    "\n",
    "train_x = X[:train_n, :].contiguous().cuda()\n",
    "train_y = y[:train_n].contiguous().cuda()\n",
    "\n",
    "test_x = X[train_n:, :].contiguous().cuda()\n",
    "test_y = y[train_n:].contiguous().cuda()\n",
    "\n",
    "mean = train_x.mean(dim=-2, keepdim=True)\n",
    "std = train_x.std(dim=-2, keepdim=True) + 1e-6\n",
    "train_x = (train_x - mean) / std\n",
    "test_x = (test_x - mean) / std\n",
    "\n",
    "mean,std = train_y.mean(),train_y.std()\n",
    "train_y = (train_y - mean) / std\n",
    "test_y = (test_y - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=False)\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadratureDist(pyro.distributions.Distribution):\n",
    "    def __init__(self, likelihood, function_dist):\n",
    "        self.likelihood = likelihood\n",
    "        self.function_dist = function_dist\n",
    "\n",
    "    def log_prob(self, target):\n",
    "        return self.likelihood.expected_log_prob(target, self.function_dist)\n",
    "\n",
    "    def sample(self, sample_shape=torch.Size()):\n",
    "        pass\n",
    "\n",
    "\n",
    "class AbstractPyroHiddenGPLayer(PyroVariationalGP):\n",
    "    def __init__(self, variational_strategy, input_dims, output_dims, num_samples, num_data, name_prefix=\"\"):\n",
    "        super().__init__(variational_strategy, None, num_data, name_prefix)\n",
    "        self.input_dims = input_dims\n",
    "        self.output_dims = output_dims\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def model(self, input, output, *params, **kwargs):\n",
    "        \"\"\"\n",
    "        Hidden GP layers do not implement models, only guides.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"\n",
    "        input: num_samples x num_data x d\n",
    "        intermediate: num_samples x output_dims x num_data\n",
    "        outputs: num_samples x num_data x output_dims\n",
    "        \"\"\"\n",
    "        inputs = inputs.contiguous()\n",
    "        if inputs.dim() == 2:\n",
    "            # Assume new input entirely\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "            inputs = inputs.expand(self.output_dims, inputs.size(-2), self.input_dims)\n",
    "        elif inputs.dim() == 3:\n",
    "            # Assume batch dim is samples, not output_dim\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "            inputs = inputs.expand(self.output_dims, inputs.size(1), inputs.size(-2), self.input_dims)\n",
    "\n",
    "        if inputs.dim() == 4:\n",
    "            num_samples = inputs.size(-3)\n",
    "            inputs = inputs.view(self.output_dims, inputs.size(-2) * inputs.size(-3), self.input_dims)\n",
    "            reshape_output = True\n",
    "        else:\n",
    "            reshape_output = False\n",
    "            num_samples = self.num_samples\n",
    "        \n",
    "        qf = super().__call__(inputs)\n",
    "        \n",
    "        if reshape_output:\n",
    "            samples = qf.rsample()\n",
    "            samples = samples.view(self.output_dims, num_samples, -1).permute(1, 2, 0)\n",
    "        else:\n",
    "            samples = qf.rsample(torch.Size([num_samples]))\n",
    "            samples = samples.transpose(-2, -1)\n",
    "        \n",
    "        return samples.contiguous()\n",
    "        \n",
    "\n",
    "class PyroDeepGP(AbstractPyroHiddenGPLayer):\n",
    "    def __init__(self, variational_strategy, likelihood, input_dims, output_dims, num_samples, num_data, hidden_gp_net, name_prefix=\"\"):\n",
    "        super().__init__(variational_strategy, input_dims, output_dims, num_samples, num_data, name_prefix)\n",
    "        \n",
    "        self.likelihood = likelihood\n",
    "        self.hidden_gp_net = hidden_gp_net\n",
    "    \n",
    "    def guide(self, input, output, *params, **kwargs):\n",
    "        for hidden_layer in self.hidden_gp_net:\n",
    "            pyro.module(hidden_layer.name_prefix + \".gp_prior\", hidden_layer)\n",
    "#             hidden_layer.sample_inducing_values(hidden_layer.variational_distribution)\n",
    "            input = hidden_layer(input)  # Propagate input\n",
    "\n",
    "        # Guide for output layer\n",
    "        super().guide(input, output, *params, **kwargs)\n",
    "    \n",
    "    def model(self, input, output, *params, **kwargs):\n",
    "        inputs = self.hidden_gp_net(input)\n",
    "        # inputs is now num_samples x num_data x num_last_hidden\n",
    "        \n",
    "        # q(f) = num_samples x num_data\n",
    "        \n",
    "        if inputs.dim() == 2:\n",
    "            # Assume new input entirely\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "            inputs = inputs.expand(self.output_dims, inputs.size(-2), self.input_dims)\n",
    "        elif inputs.dim() == 3:\n",
    "            # Assume batch dim is samples, not output_dim\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "            inputs = inputs.expand(self.output_dims, inputs.size(1), inputs.size(-2), self.input_dims)\n",
    "\n",
    "        if inputs.dim() == 4:\n",
    "            num_samples = inputs.size(-3)\n",
    "            inputs = inputs.view(self.output_dims, inputs.size(-2) * inputs.size(-3), self.input_dims)\n",
    "            reshape_output = True\n",
    "        else:\n",
    "            reshape_output = False\n",
    "            num_samples = self.num_samples\n",
    "\n",
    "        pyro.module(self.name_prefix + \".gp_prior\", self)\n",
    "\n",
    "        inducing_points = self.variational_strategy.inducing_points\n",
    "        num_induc = inducing_points.size(-2)\n",
    "        full_inputs = torch.cat([inducing_points, inputs], dim=-2)\n",
    "        full_output = self.forward(full_inputs)\n",
    "        full_mean, full_covar = full_output.mean, full_output.lazy_covariance_matrix\n",
    "\n",
    "        # Mean terms\n",
    "        induc_mean = full_mean[..., :num_induc]\n",
    "        test_mean = full_mean[..., num_induc:]\n",
    "\n",
    "        # Covariance terms\n",
    "        induc_induc_covar = full_covar[..., :num_induc, :num_induc].add_jitter()\n",
    "        induc_induc_covar = gpytorch.lazy.CholLazyTensor(induc_induc_covar.cholesky())\n",
    "        induc_data_covar = full_covar[..., :num_induc, num_induc:].evaluate()\n",
    "        data_data_covar = full_covar[..., num_induc:, num_induc:]\n",
    "\n",
    "        # Prior distribution + samples\n",
    "        prior_distribution = full_output.__class__(induc_mean, induc_induc_covar)\n",
    "        inducing_values_samples = self.sample_inducing_values(prior_distribution)\n",
    "\n",
    "        means = induc_data_covar.transpose(-2, -1).matmul(induc_induc_covar.inv_matmul(inducing_values_samples.unsqueeze(-1))).squeeze(-1)\n",
    "        \n",
    "        means_ = means.reshape(num_samples, -1)\n",
    "        vars_ = torch.sqrt((\n",
    "                data_data_covar.diag() - induc_induc_covar.inv_quad(induc_data_covar, reduce_inv_quad=False)\n",
    "            ).clamp_min(0))\n",
    "        vars_ = vars_.reshape(num_samples, -1)\n",
    "        \n",
    "        \n",
    "        f_samples = pyro.distributions.Normal(\n",
    "            means_,\n",
    "            vars_,\n",
    "        )\n",
    "        \n",
    "        # f_samples is Normal(num_samples x num_data)\n",
    "        \n",
    "        with pyro.plate(self.name_prefix + \".samples_plate\", f_samples.batch_shape[-2], dim=-2):\n",
    "            with pyro.plate(self.name_prefix + \".data_plate\", f_samples.batch_shape[-1], dim=-1):\n",
    "                with pyro.poutine.scale(scale=float(self.num_data / input.size(-2))):\n",
    "                    out_dist = QuadratureDist(self.likelihood, f_samples)\n",
    "                    return pyro.sample(self.name_prefix + \".output_value\", out_dist, obs=output)\n",
    "\n",
    "        \n",
    "    def __call__(self, inputs):\n",
    "        inputs = self.hidden_gp_net(inputs)\n",
    "        \n",
    "        if inputs.dim() == 2:\n",
    "            # Assume new input entirely\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "            inputs = inputs.expand(self.output_dims, inputs.size(-2), self.input_dims)\n",
    "        elif inputs.dim() == 3:\n",
    "            # Assume batch dim is samples, not output_dim\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "            inputs = inputs.expand(self.output_dims, inputs.size(1), inputs.size(-2), self.input_dims)\n",
    "\n",
    "        if inputs.dim() == 4:\n",
    "            num_samples = inputs.size(-3)\n",
    "            inputs = inputs.view(self.output_dims, inputs.size(-2) * inputs.size(-3), self.input_dims)\n",
    "            reshape_output = True\n",
    "        else:\n",
    "            reshape_output = False\n",
    "            num_samples = self.num_samples\n",
    "            \n",
    "        output = PyroVariationalGP.__call__(self, inputs)\n",
    "        \n",
    "        mean_ = output.mean\n",
    "        var_ = output.variance\n",
    "        \n",
    "        mean_ = mean_.reshape(num_samples, -1)\n",
    "        var_ = var_.reshape(num_samples, -1)\n",
    "        \n",
    "        return output.__class__(\n",
    "            mean_,\n",
    "            gpytorch.lazy.DiagLazyTensor(var_),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleHiddenLayer(AbstractPyroHiddenGPLayer):\n",
    "    def __init__(self, input_dims, output_dims, num_samples, num_data, num_inducing=512, name_prefix=\"\"):\n",
    "        inducing_points = torch.randn(output_dims, num_inducing, input_dims)\n",
    "\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            num_inducing_points=num_inducing,\n",
    "            batch_size=output_dims\n",
    "        )\n",
    "\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True\n",
    "        )\n",
    "        \n",
    "        super().__init__(variational_strategy, input_dims, output_dims, num_samples, num_data, name_prefix)\n",
    "\n",
    "        self.mean_module = ConstantMean(batch_size=output_dims)\n",
    "        self.covar_module = ScaleKernel(RBFKernel(batch_size=output_dims,\n",
    "                                                  ard_num_dims=input_dims), batch_size=output_dims,\n",
    "                                        ard_num_dims=None)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "class SimpleDeepGP(PyroDeepGP):\n",
    "    def __init__(self, input_dims, output_dims, num_samples, num_data, hidden_gp_net, num_inducing=512, name_prefix=\"\"):\n",
    "        inducing_points = torch.randn(output_dims, num_inducing, input_dims)\n",
    "\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            num_inducing_points=num_inducing,\n",
    "            batch_size=output_dims\n",
    "        )\n",
    "\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True\n",
    "        )\n",
    "        \n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        \n",
    "        super().__init__(\n",
    "            variational_strategy,\n",
    "            likelihood,\n",
    "            input_dims,\n",
    "            output_dims,\n",
    "            num_samples,\n",
    "            num_data,\n",
    "            hidden_gp_net,\n",
    "            name_prefix,\n",
    "        )\n",
    "\n",
    "        self.mean_module = ConstantMean(batch_size=output_dims)\n",
    "        self.covar_module = ScaleKernel(RBFKernel(batch_size=output_dims,\n",
    "                                                  ard_num_dims=input_dims), batch_size=output_dims,\n",
    "                                    ard_num_dims=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13279, 18])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "hidden_gp1 = SimpleHiddenLayer(\n",
    "    input_dims=train_x.size(-1), \n",
    "    output_dims=10,\n",
    "    num_samples=5,\n",
    "    num_data=train_x.size(-2),\n",
    "    name_prefix=\"hidden_gp1\"\n",
    ").cuda()\n",
    "\n",
    "hidden_gp2 = SimpleHiddenLayer(\n",
    "    input_dims=10,\n",
    "    output_dims=10,\n",
    "    num_samples=5,\n",
    "    num_data=train_x.size(-2),\n",
    "    name_prefix=\"hidden_gp2\"\n",
    ").cuda()\n",
    "\n",
    "hidden_gp_net = torch.nn.Sequential(\n",
    "    hidden_gp1,\n",
    "    hidden_gp2,\n",
    ")\n",
    "\n",
    "deep_gp = SimpleDeepGP(10, 1, 5, train_x.size(-2), hidden_gp_net, name_prefix=\"output_gp\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_gp(train_x[:1024, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_gp.model(train_x[:1024, :], train_y[:1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_gp.guide(train_x[:1024, :], train_y[:1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "from pyro import optim\n",
    "# optimizer = optim.Adam({\"lr\": lr})\n",
    "scheduler = pyro.optim.MultiStepLR({\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'optim_args': {'lr': 0.01},\n",
    "    'milestones': [0.75 * num_epochs],\n",
    "    'gamma': 0.5}\n",
    ")\n",
    "elbo = pyro.infer.Trace_ELBO(num_particles=1, vectorize_particles=True)\n",
    "svi = pyro.infer.SVI(deep_gp.model, deep_gp.guide, scheduler, elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Guessed max_plate_nesting = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1/780\tloss: 121024.531\n",
      "Iter: 2/780\tloss: 124045.125\n",
      "Iter: 3/780\tloss: 127748.148\n",
      "Iter: 4/780\tloss: 128445.391\n",
      "Iter: 5/780\tloss: 130713.203\n",
      "Iter: 6/780\tloss: 128700.000\n",
      "Iter: 7/780\tloss: 131327.391\n",
      "Iter: 8/780\tloss: 125699.977\n",
      "Iter: 9/780\tloss: 126386.445\n",
      "Iter: 10/780\tloss: 132934.094\n",
      "Iter: 11/780\tloss: 133077.172\n",
      "Iter: 12/780\tloss: 131425.547\n",
      "Iter: 13/780\tloss: 140960.859\n",
      "Iter: 14/780\tloss: 127055.781\n",
      "Iter: 15/780\tloss: 133786.188\n",
      "Iter: 16/780\tloss: 135585.562\n",
      "Iter: 17/780\tloss: 128565.656\n",
      "Iter: 18/780\tloss: 128022.211\n",
      "Iter: 19/780\tloss: 133863.188\n",
      "Iter: 20/780\tloss: 131440.781\n",
      "Iter: 21/780\tloss: 128582.406\n",
      "Iter: 22/780\tloss: 131624.719\n",
      "Iter: 23/780\tloss: 127233.883\n",
      "Iter: 24/780\tloss: 134449.062\n",
      "Iter: 25/780\tloss: 125803.367\n",
      "Iter: 26/780\tloss: 133936.703\n",
      "Iter: 27/780\tloss: 121528.586\n",
      "Iter: 28/780\tloss: 124806.398\n",
      "Iter: 29/780\tloss: 128201.875\n",
      "Iter: 30/780\tloss: 128603.617\n",
      "Iter: 31/780\tloss: 130918.320\n",
      "Iter: 32/780\tloss: 128439.867\n",
      "Iter: 33/780\tloss: 131332.578\n",
      "Iter: 34/780\tloss: 125747.000\n",
      "Iter: 35/780\tloss: 126349.016\n",
      "Iter: 36/780\tloss: 132984.797\n",
      "Iter: 37/780\tloss: 133383.594\n",
      "Iter: 38/780\tloss: 131069.898\n",
      "Iter: 39/780\tloss: 140689.609\n",
      "Iter: 40/780\tloss: 126936.680\n",
      "Iter: 41/780\tloss: 134148.766\n",
      "Iter: 42/780\tloss: 135091.125\n",
      "Iter: 43/780\tloss: 128151.141\n",
      "Iter: 44/780\tloss: 128577.281\n",
      "Iter: 45/780\tloss: 134302.469\n",
      "Iter: 46/780\tloss: 131255.484\n",
      "Iter: 47/780\tloss: 128014.547\n",
      "Iter: 48/780\tloss: 131376.359\n",
      "Iter: 49/780\tloss: 127072.523\n",
      "Iter: 50/780\tloss: 134851.203\n",
      "Iter: 51/780\tloss: 125017.555\n",
      "Iter: 52/780\tloss: 133425.516\n",
      "Iter: 53/780\tloss: 121640.203\n",
      "Iter: 54/780\tloss: 124534.242\n",
      "Iter: 55/780\tloss: 128384.703\n",
      "Iter: 56/780\tloss: 128493.992\n",
      "Iter: 57/780\tloss: 131327.000\n",
      "Iter: 58/780\tloss: 128750.508\n",
      "Iter: 59/780\tloss: 131156.781\n",
      "Iter: 60/780\tloss: 125884.109\n",
      "Iter: 61/780\tloss: 126849.719\n",
      "Iter: 62/780\tloss: 133008.891\n",
      "Iter: 63/780\tloss: 133260.453\n",
      "Iter: 64/780\tloss: 130917.453\n",
      "Iter: 65/780\tloss: 140622.016\n",
      "Iter: 66/780\tloss: 127294.688\n",
      "Iter: 67/780\tloss: 134129.359\n",
      "Iter: 68/780\tloss: 135167.188\n",
      "Iter: 69/780\tloss: 127938.945\n",
      "Iter: 70/780\tloss: 128678.844\n",
      "Iter: 71/780\tloss: 134046.094\n",
      "Iter: 72/780\tloss: 131331.781\n",
      "Iter: 73/780\tloss: 128342.695\n",
      "Iter: 74/780\tloss: 131223.609\n",
      "Iter: 75/780\tloss: 127473.992\n",
      "Iter: 76/780\tloss: 134574.953\n",
      "Iter: 77/780\tloss: 125416.805\n",
      "Iter: 78/780\tloss: 133358.250\n",
      "Iter: 79/780\tloss: 121332.750\n",
      "Iter: 80/780\tloss: 124452.188\n",
      "Iter: 81/780\tloss: 128844.070\n",
      "Iter: 82/780\tloss: 128758.625\n",
      "Iter: 83/780\tloss: 130265.812\n",
      "Iter: 84/780\tloss: 128780.297\n",
      "Iter: 85/780\tloss: 131158.047\n",
      "Iter: 86/780\tloss: 125714.625\n",
      "Iter: 87/780\tloss: 126213.789\n",
      "Iter: 88/780\tloss: 132621.422\n",
      "Iter: 89/780\tloss: 133506.266\n",
      "Iter: 90/780\tloss: 130959.953\n",
      "Iter: 91/780\tloss: 140462.094\n",
      "Iter: 92/780\tloss: 127205.633\n",
      "Iter: 93/780\tloss: 134238.172\n",
      "Iter: 94/780\tloss: 135001.031\n",
      "Iter: 95/780\tloss: 128078.391\n",
      "Iter: 96/780\tloss: 128325.289\n",
      "Iter: 97/780\tloss: 134052.266\n",
      "Iter: 98/780\tloss: 130837.125\n",
      "Iter: 99/780\tloss: 128602.391\n",
      "Iter: 100/780\tloss: 131546.062\n",
      "Iter: 101/780\tloss: 127394.570\n",
      "Iter: 102/780\tloss: 134856.312\n",
      "Iter: 103/780\tloss: 125076.789\n",
      "Iter: 104/780\tloss: 133399.406\n",
      "Iter: 105/780\tloss: 121142.727\n",
      "Iter: 106/780\tloss: 124272.023\n",
      "Iter: 107/780\tloss: 128273.578\n",
      "Iter: 108/780\tloss: 128868.695\n",
      "Iter: 109/780\tloss: 130822.523\n",
      "Iter: 110/780\tloss: 128580.766\n",
      "Iter: 111/780\tloss: 131928.297\n",
      "Iter: 112/780\tloss: 126054.281\n",
      "Iter: 113/780\tloss: 126823.164\n",
      "Iter: 114/780\tloss: 132721.156\n",
      "Iter: 115/780\tloss: 133298.797\n",
      "Iter: 116/780\tloss: 131311.469\n",
      "Iter: 117/780\tloss: 140435.734\n",
      "Iter: 118/780\tloss: 126837.617\n",
      "Iter: 119/780\tloss: 134014.734\n",
      "Iter: 120/780\tloss: 135242.188\n",
      "Iter: 121/780\tloss: 128170.125\n",
      "Iter: 122/780\tloss: 128434.430\n",
      "Iter: 123/780\tloss: 134157.141\n",
      "Iter: 124/780\tloss: 131107.453\n",
      "Iter: 125/780\tloss: 128316.289\n",
      "Iter: 126/780\tloss: 131296.547\n",
      "Iter: 127/780\tloss: 127179.594\n",
      "Iter: 128/780\tloss: 134678.469\n",
      "Iter: 129/780\tloss: 125077.945\n",
      "Iter: 130/780\tloss: 134100.547\n",
      "Iter: 131/780\tloss: 121239.789\n",
      "Iter: 132/780\tloss: 124711.148\n",
      "Iter: 133/780\tloss: 128063.461\n",
      "Iter: 134/780\tloss: 128412.430\n",
      "Iter: 135/780\tloss: 130955.469\n",
      "Iter: 136/780\tloss: 128610.273\n",
      "Iter: 137/780\tloss: 131042.094\n",
      "Iter: 138/780\tloss: 125866.328\n",
      "Iter: 139/780\tloss: 126575.555\n",
      "Iter: 140/780\tloss: 132935.594\n",
      "Iter: 141/780\tloss: 132986.125\n",
      "Iter: 142/780\tloss: 131579.562\n",
      "Iter: 143/780\tloss: 141475.844\n",
      "Iter: 144/780\tloss: 127001.094\n",
      "Iter: 145/780\tloss: 134332.750\n",
      "Iter: 146/780\tloss: 134873.969\n",
      "Iter: 147/780\tloss: 128326.586\n",
      "Iter: 148/780\tloss: 128657.641\n",
      "Iter: 149/780\tloss: 133808.234\n",
      "Iter: 150/780\tloss: 131114.297\n",
      "Iter: 151/780\tloss: 128513.914\n",
      "Iter: 152/780\tloss: 131273.203\n",
      "Iter: 153/780\tloss: 127559.484\n",
      "Iter: 154/780\tloss: 134910.609\n",
      "Iter: 155/780\tloss: 125619.977\n",
      "Iter: 156/780\tloss: 134147.562\n",
      "Iter: 157/780\tloss: 120913.945\n",
      "Iter: 158/780\tloss: 124358.719\n",
      "Iter: 159/780\tloss: 128005.805\n",
      "Iter: 160/780\tloss: 128650.125\n",
      "Iter: 161/780\tloss: 130768.789\n",
      "Iter: 162/780\tloss: 128682.875\n",
      "Iter: 163/780\tloss: 131253.109\n",
      "Iter: 164/780\tloss: 125857.008\n",
      "Iter: 165/780\tloss: 126247.445\n",
      "Iter: 166/780\tloss: 132974.422\n",
      "Iter: 167/780\tloss: 133269.188\n",
      "Iter: 168/780\tloss: 131295.969\n",
      "Iter: 169/780\tloss: 140548.906\n",
      "Iter: 170/780\tloss: 127434.000\n",
      "Iter: 171/780\tloss: 133954.641\n",
      "Iter: 172/780\tloss: 135198.641\n",
      "Iter: 173/780\tloss: 128480.461\n",
      "Iter: 174/780\tloss: 128360.102\n",
      "Iter: 175/780\tloss: 133949.875\n",
      "Iter: 176/780\tloss: 131172.906\n",
      "Iter: 177/780\tloss: 128098.797\n",
      "Iter: 178/780\tloss: 131554.062\n",
      "Iter: 179/780\tloss: 127209.938\n",
      "Iter: 180/780\tloss: 134530.859\n",
      "Iter: 181/780\tloss: 125248.078\n",
      "Iter: 182/780\tloss: 133755.781\n",
      "Iter: 183/780\tloss: 121171.648\n",
      "Iter: 184/780\tloss: 124406.695\n",
      "Iter: 185/780\tloss: 128942.797\n",
      "Iter: 186/780\tloss: 128594.289\n",
      "Iter: 187/780\tloss: 130666.500\n",
      "Iter: 188/780\tloss: 128875.422\n",
      "Iter: 189/780\tloss: 131107.969\n",
      "Iter: 190/780\tloss: 125710.586\n",
      "Iter: 191/780\tloss: 126547.945\n",
      "Iter: 192/780\tloss: 132870.125\n",
      "Iter: 193/780\tloss: 132708.250\n",
      "Iter: 194/780\tloss: 131230.562\n",
      "Iter: 195/780\tloss: 141095.453\n",
      "Iter: 196/780\tloss: 127292.406\n",
      "Iter: 197/780\tloss: 133982.750\n",
      "Iter: 198/780\tloss: 135210.000\n",
      "Iter: 199/780\tloss: 128342.047\n",
      "Iter: 200/780\tloss: 128859.062\n",
      "Iter: 201/780\tloss: 134124.406\n",
      "Iter: 202/780\tloss: 131197.609\n",
      "Iter: 203/780\tloss: 128275.805\n",
      "Iter: 204/780\tloss: 131596.438\n",
      "Iter: 205/780\tloss: 127534.836\n",
      "Iter: 206/780\tloss: 135156.422\n",
      "Iter: 207/780\tloss: 125096.117\n",
      "Iter: 208/780\tloss: 133767.250\n",
      "Iter: 209/780\tloss: 121234.719\n",
      "Iter: 210/780\tloss: 124597.016\n",
      "Iter: 211/780\tloss: 128475.836\n",
      "Iter: 212/780\tloss: 128628.367\n",
      "Iter: 213/780\tloss: 130943.859\n",
      "Iter: 214/780\tloss: 128456.055\n",
      "Iter: 215/780\tloss: 131129.000\n",
      "Iter: 216/780\tloss: 126213.422\n",
      "Iter: 217/780\tloss: 126632.367\n",
      "Iter: 218/780\tloss: 132831.500\n",
      "Iter: 219/780\tloss: 133402.344\n",
      "Iter: 220/780\tloss: 130894.805\n",
      "Iter: 221/780\tloss: 140857.250\n",
      "Iter: 222/780\tloss: 127236.148\n",
      "Iter: 223/780\tloss: 134037.312\n",
      "Iter: 224/780\tloss: 135470.875\n",
      "Iter: 225/780\tloss: 128173.531\n",
      "Iter: 226/780\tloss: 128652.852\n",
      "Iter: 227/780\tloss: 134426.406\n",
      "Iter: 228/780\tloss: 130847.469\n",
      "Iter: 229/780\tloss: 128388.094\n",
      "Iter: 230/780\tloss: 131388.750\n",
      "Iter: 231/780\tloss: 127221.375\n",
      "Iter: 232/780\tloss: 135309.375\n",
      "Iter: 233/780\tloss: 124761.234\n",
      "Iter: 234/780\tloss: 133867.531\n",
      "Iter: 235/780\tloss: 120689.484\n",
      "Iter: 236/780\tloss: 124532.047\n",
      "Iter: 237/780\tloss: 128006.969\n",
      "Iter: 238/780\tloss: 128493.414\n",
      "Iter: 239/780\tloss: 130679.039\n",
      "Iter: 240/780\tloss: 128616.766\n",
      "Iter: 241/780\tloss: 131300.391\n",
      "Iter: 242/780\tloss: 125830.062\n",
      "Iter: 243/780\tloss: 126379.383\n",
      "Iter: 244/780\tloss: 133093.500\n",
      "Iter: 245/780\tloss: 133516.312\n",
      "Iter: 246/780\tloss: 131386.266\n",
      "Iter: 247/780\tloss: 141043.641\n",
      "Iter: 248/780\tloss: 127215.656\n",
      "Iter: 249/780\tloss: 133964.453\n",
      "Iter: 250/780\tloss: 135335.969\n",
      "Iter: 251/780\tloss: 128255.406\n",
      "Iter: 252/780\tloss: 128289.727\n",
      "Iter: 253/780\tloss: 133709.812\n",
      "Iter: 254/780\tloss: 130749.547\n",
      "Iter: 255/780\tloss: 128132.922\n",
      "Iter: 256/780\tloss: 131649.922\n",
      "Iter: 257/780\tloss: 127443.344\n",
      "Iter: 258/780\tloss: 134529.156\n",
      "Iter: 259/780\tloss: 125388.867\n",
      "Iter: 260/780\tloss: 133802.516\n",
      "Iter: 261/780\tloss: 121188.383\n",
      "Iter: 262/780\tloss: 124946.953\n",
      "Iter: 263/780\tloss: 128710.047\n",
      "Iter: 264/780\tloss: 129027.984\n",
      "Iter: 265/780\tloss: 130713.914\n",
      "Iter: 266/780\tloss: 128442.477\n",
      "Iter: 267/780\tloss: 131184.359\n",
      "Iter: 268/780\tloss: 126031.602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 269/780\tloss: 126699.953\n",
      "Iter: 270/780\tloss: 132634.438\n",
      "Iter: 271/780\tloss: 133576.547\n",
      "Iter: 272/780\tloss: 131214.422\n",
      "Iter: 273/780\tloss: 140694.203\n",
      "Iter: 274/780\tloss: 127249.188\n",
      "Iter: 275/780\tloss: 134529.250\n",
      "Iter: 276/780\tloss: 135162.328\n",
      "Iter: 277/780\tloss: 128867.969\n",
      "Iter: 278/780\tloss: 128598.203\n",
      "Iter: 279/780\tloss: 134341.266\n",
      "Iter: 280/780\tloss: 131320.734\n",
      "Iter: 281/780\tloss: 128159.828\n",
      "Iter: 282/780\tloss: 131204.547\n",
      "Iter: 283/780\tloss: 127319.906\n",
      "Iter: 284/780\tloss: 134853.578\n",
      "Iter: 285/780\tloss: 125131.406\n",
      "Iter: 286/780\tloss: 133238.672\n",
      "Iter: 287/780\tloss: 120747.500\n",
      "Iter: 288/780\tloss: 124683.984\n",
      "Iter: 289/780\tloss: 128303.672\n",
      "Iter: 290/780\tloss: 128924.477\n",
      "Iter: 291/780\tloss: 130751.094\n",
      "Iter: 292/780\tloss: 128381.703\n",
      "Iter: 293/780\tloss: 130955.008\n",
      "Iter: 294/780\tloss: 125804.492\n",
      "Iter: 295/780\tloss: 126421.883\n",
      "Iter: 296/780\tloss: 132835.641\n",
      "Iter: 297/780\tloss: 133674.891\n",
      "Iter: 298/780\tloss: 131071.578\n",
      "Iter: 299/780\tloss: 140531.469\n",
      "Iter: 300/780\tloss: 127142.578\n",
      "Iter: 301/780\tloss: 134429.219\n",
      "Iter: 302/780\tloss: 135363.406\n",
      "Iter: 303/780\tloss: 128719.812\n",
      "Iter: 304/780\tloss: 128477.867\n",
      "Iter: 305/780\tloss: 134308.797\n",
      "Iter: 306/780\tloss: 130920.484\n",
      "Iter: 307/780\tloss: 128592.406\n",
      "Iter: 308/780\tloss: 131258.141\n",
      "Iter: 309/780\tloss: 127460.422\n",
      "Iter: 310/780\tloss: 134767.672\n",
      "Iter: 311/780\tloss: 125472.070\n",
      "Iter: 312/780\tloss: 133513.781\n",
      "Iter: 313/780\tloss: 121301.047\n",
      "Iter: 314/780\tloss: 124258.070\n",
      "Iter: 315/780\tloss: 128257.250\n",
      "Iter: 316/780\tloss: 128450.336\n",
      "Iter: 317/780\tloss: 130541.328\n",
      "Iter: 318/780\tloss: 128733.891\n",
      "Iter: 319/780\tloss: 131160.609\n",
      "Iter: 320/780\tloss: 126037.039\n",
      "Iter: 321/780\tloss: 126361.992\n",
      "Iter: 322/780\tloss: 133003.969\n",
      "Iter: 323/780\tloss: 133198.125\n",
      "Iter: 324/780\tloss: 131225.531\n",
      "Iter: 325/780\tloss: 140308.078\n",
      "Iter: 326/780\tloss: 126988.961\n",
      "Iter: 327/780\tloss: 133811.797\n",
      "Iter: 328/780\tloss: 135161.297\n",
      "Iter: 329/780\tloss: 127937.516\n",
      "Iter: 330/780\tloss: 127933.023\n",
      "Iter: 331/780\tloss: 133811.578\n",
      "Iter: 332/780\tloss: 131388.703\n",
      "Iter: 333/780\tloss: 128442.523\n",
      "Iter: 334/780\tloss: 131940.391\n",
      "Iter: 335/780\tloss: 127209.812\n",
      "Iter: 336/780\tloss: 134844.828\n",
      "Iter: 337/780\tloss: 125357.500\n",
      "Iter: 338/780\tloss: 133670.281\n",
      "Iter: 339/780\tloss: 120868.391\n",
      "Iter: 340/780\tloss: 124184.297\n",
      "Iter: 341/780\tloss: 128188.891\n",
      "Iter: 342/780\tloss: 128949.875\n",
      "Iter: 343/780\tloss: 130807.047\n",
      "Iter: 344/780\tloss: 128298.195\n",
      "Iter: 345/780\tloss: 131017.688\n",
      "Iter: 346/780\tloss: 126147.539\n",
      "Iter: 347/780\tloss: 126212.070\n",
      "Iter: 348/780\tloss: 132768.375\n",
      "Iter: 349/780\tloss: 133401.656\n",
      "Iter: 350/780\tloss: 131382.234\n",
      "Iter: 351/780\tloss: 140961.641\n",
      "Iter: 352/780\tloss: 127024.711\n",
      "Iter: 353/780\tloss: 134144.609\n",
      "Iter: 354/780\tloss: 135306.750\n",
      "Iter: 355/780\tloss: 128504.281\n",
      "Iter: 356/780\tloss: 128671.820\n",
      "Iter: 357/780\tloss: 134166.438\n",
      "Iter: 358/780\tloss: 131126.094\n",
      "Iter: 359/780\tloss: 128141.414\n",
      "Iter: 360/780\tloss: 131418.766\n",
      "Iter: 361/780\tloss: 127496.062\n",
      "Iter: 362/780\tloss: 134748.234\n",
      "Iter: 363/780\tloss: 125630.430\n",
      "Iter: 364/780\tloss: 133280.172\n",
      "Iter: 365/780\tloss: 120862.578\n",
      "Iter: 366/780\tloss: 124641.914\n",
      "Iter: 367/780\tloss: 128054.133\n",
      "Iter: 368/780\tloss: 128546.266\n",
      "Iter: 369/780\tloss: 130807.875\n",
      "Iter: 370/780\tloss: 128474.086\n",
      "Iter: 371/780\tloss: 130819.516\n",
      "Iter: 372/780\tloss: 126028.812\n",
      "Iter: 373/780\tloss: 126534.414\n",
      "Iter: 374/780\tloss: 132773.984\n",
      "Iter: 375/780\tloss: 133183.703\n",
      "Iter: 376/780\tloss: 131031.555\n",
      "Iter: 377/780\tloss: 140611.516\n",
      "Iter: 378/780\tloss: 127377.086\n",
      "Iter: 379/780\tloss: 134057.203\n",
      "Iter: 380/780\tloss: 135386.000\n",
      "Iter: 381/780\tloss: 128388.797\n",
      "Iter: 382/780\tloss: 128051.523\n",
      "Iter: 383/780\tloss: 134091.938\n",
      "Iter: 384/780\tloss: 131076.547\n",
      "Iter: 385/780\tloss: 128472.773\n",
      "Iter: 386/780\tloss: 131493.969\n",
      "Iter: 387/780\tloss: 127046.164\n",
      "Iter: 388/780\tloss: 135072.953\n",
      "Iter: 389/780\tloss: 125202.141\n",
      "Iter: 390/780\tloss: 133895.844\n",
      "Iter: 391/780\tloss: 121010.234\n",
      "Iter: 392/780\tloss: 125059.117\n",
      "Iter: 393/780\tloss: 128079.234\n",
      "Iter: 394/780\tloss: 128359.891\n",
      "Iter: 395/780\tloss: 130432.109\n",
      "Iter: 396/780\tloss: 128523.195\n",
      "Iter: 397/780\tloss: 131296.969\n",
      "Iter: 398/780\tloss: 126122.344\n",
      "Iter: 399/780\tloss: 126163.141\n",
      "Iter: 400/780\tloss: 132957.562\n",
      "Iter: 401/780\tloss: 132978.188\n",
      "Iter: 402/780\tloss: 131248.516\n",
      "Iter: 403/780\tloss: 140517.188\n",
      "Iter: 404/780\tloss: 126863.344\n",
      "Iter: 405/780\tloss: 134365.859\n",
      "Iter: 406/780\tloss: 135182.031\n",
      "Iter: 407/780\tloss: 127879.070\n",
      "Iter: 408/780\tloss: 128924.047\n",
      "Iter: 409/780\tloss: 134064.750\n",
      "Iter: 410/780\tloss: 131042.844\n",
      "Iter: 411/780\tloss: 128410.055\n",
      "Iter: 412/780\tloss: 131422.516\n",
      "Iter: 413/780\tloss: 127600.742\n",
      "Iter: 414/780\tloss: 134841.578\n",
      "Iter: 415/780\tloss: 125787.742\n",
      "Iter: 416/780\tloss: 133384.969\n",
      "Iter: 417/780\tloss: 121191.062\n",
      "Iter: 418/780\tloss: 124442.414\n",
      "Iter: 419/780\tloss: 128074.273\n",
      "Iter: 420/780\tloss: 128571.500\n",
      "Iter: 421/780\tloss: 130985.992\n",
      "Iter: 422/780\tloss: 128780.781\n",
      "Iter: 423/780\tloss: 131334.125\n",
      "Iter: 424/780\tloss: 125962.445\n",
      "Iter: 425/780\tloss: 126743.945\n",
      "Iter: 426/780\tloss: 132843.875\n",
      "Iter: 427/780\tloss: 132789.578\n",
      "Iter: 428/780\tloss: 131390.266\n",
      "Iter: 429/780\tloss: 140939.406\n",
      "Iter: 430/780\tloss: 126689.422\n",
      "Iter: 431/780\tloss: 134365.859\n",
      "Iter: 432/780\tloss: 135447.531\n",
      "Iter: 433/780\tloss: 128321.367\n",
      "Iter: 434/780\tloss: 128479.531\n",
      "Iter: 435/780\tloss: 134077.203\n",
      "Iter: 436/780\tloss: 130559.695\n",
      "Iter: 437/780\tloss: 127987.531\n",
      "Iter: 438/780\tloss: 131159.438\n",
      "Iter: 439/780\tloss: 126878.500\n",
      "Iter: 440/780\tloss: 134349.234\n",
      "Iter: 441/780\tloss: 125489.281\n",
      "Iter: 442/780\tloss: 133577.172\n",
      "Iter: 443/780\tloss: 121418.047\n",
      "Iter: 444/780\tloss: 124282.617\n",
      "Iter: 445/780\tloss: 128154.406\n",
      "Iter: 446/780\tloss: 128543.258\n",
      "Iter: 447/780\tloss: 130742.086\n",
      "Iter: 448/780\tloss: 128789.336\n",
      "Iter: 449/780\tloss: 131095.484\n",
      "Iter: 450/780\tloss: 125779.023\n",
      "Iter: 451/780\tloss: 126341.422\n",
      "Iter: 452/780\tloss: 132588.844\n",
      "Iter: 453/780\tloss: 133209.719\n",
      "Iter: 454/780\tloss: 131249.422\n",
      "Iter: 455/780\tloss: 140621.750\n",
      "Iter: 456/780\tloss: 126987.414\n",
      "Iter: 457/780\tloss: 133651.109\n",
      "Iter: 458/780\tloss: 135435.734\n",
      "Iter: 459/780\tloss: 128271.312\n",
      "Iter: 460/780\tloss: 128644.648\n",
      "Iter: 461/780\tloss: 133899.609\n",
      "Iter: 462/780\tloss: 131322.953\n",
      "Iter: 463/780\tloss: 128524.875\n",
      "Iter: 464/780\tloss: 131668.062\n",
      "Iter: 465/780\tloss: 127523.039\n",
      "Iter: 466/780\tloss: 134592.406\n",
      "Iter: 467/780\tloss: 124956.828\n",
      "Iter: 468/780\tloss: 133289.703\n",
      "Iter: 469/780\tloss: 121068.570\n",
      "Iter: 470/780\tloss: 124220.227\n",
      "Iter: 471/780\tloss: 128186.023\n",
      "Iter: 472/780\tloss: 128323.266\n",
      "Iter: 473/780\tloss: 131251.109\n",
      "Iter: 474/780\tloss: 128379.352\n",
      "Iter: 475/780\tloss: 131372.531\n",
      "Iter: 476/780\tloss: 125922.531\n",
      "Iter: 477/780\tloss: 126483.758\n",
      "Iter: 478/780\tloss: 133135.328\n",
      "Iter: 479/780\tloss: 133174.438\n",
      "Iter: 480/780\tloss: 131195.203\n",
      "Iter: 481/780\tloss: 141144.844\n",
      "Iter: 482/780\tloss: 126999.656\n",
      "Iter: 483/780\tloss: 133894.891\n",
      "Iter: 484/780\tloss: 135083.281\n",
      "Iter: 485/780\tloss: 127997.984\n",
      "Iter: 486/780\tloss: 128363.031\n",
      "Iter: 487/780\tloss: 134134.953\n",
      "Iter: 488/780\tloss: 131469.828\n",
      "Iter: 489/780\tloss: 128733.234\n",
      "Iter: 490/780\tloss: 131344.219\n",
      "Iter: 491/780\tloss: 127191.758\n",
      "Iter: 492/780\tloss: 134634.812\n",
      "Iter: 493/780\tloss: 125018.047\n",
      "Iter: 494/780\tloss: 133034.594\n",
      "Iter: 495/780\tloss: 120971.375\n",
      "Iter: 496/780\tloss: 124508.094\n",
      "Iter: 497/780\tloss: 128019.719\n",
      "Iter: 498/780\tloss: 128570.172\n",
      "Iter: 499/780\tloss: 130945.078\n",
      "Iter: 500/780\tloss: 128877.242\n",
      "Iter: 501/780\tloss: 131314.031\n",
      "Iter: 502/780\tloss: 126050.453\n",
      "Iter: 503/780\tloss: 126685.469\n",
      "Iter: 504/780\tloss: 132533.797\n",
      "Iter: 505/780\tloss: 133649.422\n",
      "Iter: 506/780\tloss: 131268.156\n",
      "Iter: 507/780\tloss: 140748.969\n",
      "Iter: 508/780\tloss: 126937.719\n",
      "Iter: 509/780\tloss: 134140.719\n",
      "Iter: 510/780\tloss: 134984.000\n",
      "Iter: 511/780\tloss: 128126.859\n",
      "Iter: 512/780\tloss: 128296.703\n",
      "Iter: 513/780\tloss: 133791.109\n",
      "Iter: 514/780\tloss: 131129.922\n",
      "Iter: 515/780\tloss: 128427.969\n",
      "Iter: 516/780\tloss: 131372.859\n",
      "Iter: 517/780\tloss: 127385.359\n",
      "Iter: 518/780\tloss: 134345.609\n",
      "Iter: 519/780\tloss: 125581.562\n",
      "Iter: 520/780\tloss: 133436.109\n",
      "Iter: 521/780\tloss: 121186.664\n",
      "Iter: 522/780\tloss: 124456.922\n",
      "Iter: 523/780\tloss: 128528.984\n",
      "Iter: 524/780\tloss: 128676.320\n",
      "Iter: 525/780\tloss: 130754.734\n",
      "Iter: 526/780\tloss: 128691.969\n",
      "Iter: 527/780\tloss: 131034.273\n",
      "Iter: 528/780\tloss: 126053.289\n",
      "Iter: 529/780\tloss: 126548.031\n",
      "Iter: 530/780\tloss: 133003.203\n",
      "Iter: 531/780\tloss: 133743.188\n",
      "Iter: 532/780\tloss: 131479.781\n",
      "Iter: 533/780\tloss: 141145.172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 534/780\tloss: 127175.344\n",
      "Iter: 535/780\tloss: 134441.297\n",
      "Iter: 536/780\tloss: 135248.250\n",
      "Iter: 537/780\tloss: 128473.047\n",
      "Iter: 538/780\tloss: 128750.312\n",
      "Iter: 539/780\tloss: 134571.078\n",
      "Iter: 540/780\tloss: 130849.344\n",
      "Iter: 541/780\tloss: 128564.812\n",
      "Iter: 542/780\tloss: 131494.812\n",
      "Iter: 543/780\tloss: 127536.312\n",
      "Iter: 544/780\tloss: 134853.484\n",
      "Iter: 545/780\tloss: 125547.438\n",
      "Iter: 546/780\tloss: 133832.375\n",
      "Iter: 547/780\tloss: 121418.086\n",
      "Iter: 548/780\tloss: 124354.883\n",
      "Iter: 549/780\tloss: 128310.430\n",
      "Iter: 550/780\tloss: 128668.695\n",
      "Iter: 551/780\tloss: 130742.094\n",
      "Iter: 552/780\tloss: 128499.766\n",
      "Iter: 553/780\tloss: 131237.094\n",
      "Iter: 554/780\tloss: 126411.945\n",
      "Iter: 555/780\tloss: 126403.688\n",
      "Iter: 556/780\tloss: 132737.078\n",
      "Iter: 557/780\tloss: 133179.062\n",
      "Iter: 558/780\tloss: 131155.141\n",
      "Iter: 559/780\tloss: 140747.719\n",
      "Iter: 560/780\tloss: 126862.438\n",
      "Iter: 561/780\tloss: 134323.797\n",
      "Iter: 562/780\tloss: 135377.953\n",
      "Iter: 563/780\tloss: 128302.047\n",
      "Iter: 564/780\tloss: 128689.758\n",
      "Iter: 565/780\tloss: 133983.531\n",
      "Iter: 566/780\tloss: 131145.750\n",
      "Iter: 567/780\tloss: 128165.594\n",
      "Iter: 568/780\tloss: 131167.969\n",
      "Iter: 569/780\tloss: 127687.195\n",
      "Iter: 570/780\tloss: 134769.281\n",
      "Iter: 571/780\tloss: 125204.094\n",
      "Iter: 572/780\tloss: 133568.641\n",
      "Iter: 573/780\tloss: 121232.266\n",
      "Iter: 574/780\tloss: 124693.477\n",
      "Iter: 575/780\tloss: 128268.180\n",
      "Iter: 576/780\tloss: 128613.469\n",
      "Iter: 577/780\tloss: 130708.406\n",
      "Iter: 578/780\tloss: 128546.633\n",
      "Iter: 579/780\tloss: 131337.453\n",
      "Iter: 580/780\tloss: 125623.758\n",
      "Iter: 581/780\tloss: 126590.117\n",
      "Iter: 582/780\tloss: 132769.109\n",
      "Iter: 583/780\tloss: 133396.984\n",
      "Iter: 584/780\tloss: 131422.359\n",
      "Iter: 585/780\tloss: 140771.766\n",
      "Iter: 586/780\tloss: 127091.984\n",
      "Iter: 587/780\tloss: 134686.328\n",
      "Iter: 588/780\tloss: 135248.547\n",
      "Iter: 589/780\tloss: 128079.398\n",
      "Iter: 590/780\tloss: 128302.359\n",
      "Iter: 591/780\tloss: 134432.922\n",
      "Iter: 592/780\tloss: 130942.922\n",
      "Iter: 593/780\tloss: 128101.375\n",
      "Iter: 594/780\tloss: 131381.594\n",
      "Iter: 595/780\tloss: 127266.062\n",
      "Iter: 596/780\tloss: 134759.141\n",
      "Iter: 597/780\tloss: 124946.203\n",
      "Iter: 598/780\tloss: 133631.703\n",
      "Iter: 599/780\tloss: 121172.516\n",
      "Iter: 600/780\tloss: 124860.109\n",
      "Iter: 601/780\tloss: 128384.719\n",
      "Iter: 602/780\tloss: 128766.133\n",
      "Iter: 603/780\tloss: 130682.391\n",
      "Iter: 604/780\tloss: 128721.430\n",
      "Iter: 605/780\tloss: 131106.922\n",
      "Iter: 606/780\tloss: 125834.156\n",
      "Iter: 607/780\tloss: 126361.555\n",
      "Iter: 608/780\tloss: 132949.594\n",
      "Iter: 609/780\tloss: 133200.766\n",
      "Iter: 610/780\tloss: 131022.258\n",
      "Iter: 611/780\tloss: 141027.625\n",
      "Iter: 612/780\tloss: 127220.016\n",
      "Iter: 613/780\tloss: 134278.719\n",
      "Iter: 614/780\tloss: 135016.828\n",
      "Iter: 615/780\tloss: 128020.836\n",
      "Iter: 616/780\tloss: 128733.242\n",
      "Iter: 617/780\tloss: 134059.766\n",
      "Iter: 618/780\tloss: 131208.016\n",
      "Iter: 619/780\tloss: 128396.531\n",
      "Iter: 620/780\tloss: 131004.953\n",
      "Iter: 621/780\tloss: 127240.188\n",
      "Iter: 622/780\tloss: 135151.438\n",
      "Iter: 623/780\tloss: 125770.422\n",
      "Iter: 624/780\tloss: 133427.828\n",
      "Iter: 625/780\tloss: 121022.469\n",
      "Iter: 626/780\tloss: 124187.852\n",
      "Iter: 627/780\tloss: 128110.914\n",
      "Iter: 628/780\tloss: 128485.961\n",
      "Iter: 629/780\tloss: 130839.383\n",
      "Iter: 630/780\tloss: 128525.844\n",
      "Iter: 631/780\tloss: 131194.953\n",
      "Iter: 632/780\tloss: 125770.102\n",
      "Iter: 633/780\tloss: 126957.930\n",
      "Iter: 634/780\tloss: 132765.625\n",
      "Iter: 635/780\tloss: 133237.078\n",
      "Iter: 636/780\tloss: 131378.422\n",
      "Iter: 637/780\tloss: 140810.203\n",
      "Iter: 638/780\tloss: 126996.117\n",
      "Iter: 639/780\tloss: 134191.141\n",
      "Iter: 640/780\tloss: 135435.391\n",
      "Iter: 641/780\tloss: 128359.508\n",
      "Iter: 642/780\tloss: 128459.367\n",
      "Iter: 643/780\tloss: 133841.344\n",
      "Iter: 644/780\tloss: 131194.125\n",
      "Iter: 645/780\tloss: 128560.859\n",
      "Iter: 646/780\tloss: 131268.719\n",
      "Iter: 647/780\tloss: 127560.438\n",
      "Iter: 648/780\tloss: 134743.297\n",
      "Iter: 649/780\tloss: 124961.719\n",
      "Iter: 650/780\tloss: 133239.250\n",
      "Iter: 651/780\tloss: 121003.656\n",
      "Iter: 652/780\tloss: 124959.500\n",
      "Iter: 653/780\tloss: 128488.250\n",
      "Iter: 654/780\tloss: 128975.930\n",
      "Iter: 655/780\tloss: 131008.844\n",
      "Iter: 656/780\tloss: 128860.648\n",
      "Iter: 657/780\tloss: 130820.766\n",
      "Iter: 658/780\tloss: 125361.773\n",
      "Iter: 659/780\tloss: 126603.102\n",
      "Iter: 660/780\tloss: 132838.125\n",
      "Iter: 661/780\tloss: 133482.312\n",
      "Iter: 662/780\tloss: 131191.656\n",
      "Iter: 663/780\tloss: 140769.203\n",
      "Iter: 664/780\tloss: 127511.789\n",
      "Iter: 665/780\tloss: 134112.922\n",
      "Iter: 666/780\tloss: 135180.172\n",
      "Iter: 667/780\tloss: 127919.797\n",
      "Iter: 668/780\tloss: 128109.164\n",
      "Iter: 669/780\tloss: 134194.234\n",
      "Iter: 670/780\tloss: 130662.008\n",
      "Iter: 671/780\tloss: 128645.992\n",
      "Iter: 672/780\tloss: 131598.766\n",
      "Iter: 673/780\tloss: 127596.406\n",
      "Iter: 674/780\tloss: 134857.344\n",
      "Iter: 675/780\tloss: 125483.688\n",
      "Iter: 676/780\tloss: 133950.734\n",
      "Iter: 677/780\tloss: 121035.609\n",
      "Iter: 678/780\tloss: 124416.336\n",
      "Iter: 679/780\tloss: 128620.461\n",
      "Iter: 680/780\tloss: 128568.102\n",
      "Iter: 681/780\tloss: 130614.359\n",
      "Iter: 682/780\tloss: 128920.742\n",
      "Iter: 683/780\tloss: 130894.477\n",
      "Iter: 684/780\tloss: 126336.844\n",
      "Iter: 685/780\tloss: 126834.547\n",
      "Iter: 686/780\tloss: 132796.359\n",
      "Iter: 687/780\tloss: 132690.875\n",
      "Iter: 688/780\tloss: 130651.008\n",
      "Iter: 689/780\tloss: 140496.781\n",
      "Iter: 690/780\tloss: 126840.852\n",
      "Iter: 691/780\tloss: 134365.312\n",
      "Iter: 692/780\tloss: 135606.078\n",
      "Iter: 693/780\tloss: 128569.016\n",
      "Iter: 694/780\tloss: 128359.094\n",
      "Iter: 695/780\tloss: 134149.672\n",
      "Iter: 696/780\tloss: 131211.203\n",
      "Iter: 697/780\tloss: 128787.703\n",
      "Iter: 698/780\tloss: 131175.234\n",
      "Iter: 699/780\tloss: 127261.594\n",
      "Iter: 700/780\tloss: 134804.359\n",
      "Iter: 701/780\tloss: 125393.898\n",
      "Iter: 702/780\tloss: 133359.328\n",
      "Iter: 703/780\tloss: 121211.609\n",
      "Iter: 704/780\tloss: 124414.031\n",
      "Iter: 705/780\tloss: 128338.375\n",
      "Iter: 706/780\tloss: 128393.891\n",
      "Iter: 707/780\tloss: 130705.836\n",
      "Iter: 708/780\tloss: 128399.758\n",
      "Iter: 709/780\tloss: 131080.641\n",
      "Iter: 710/780\tloss: 125816.922\n",
      "Iter: 711/780\tloss: 126253.297\n",
      "Iter: 712/780\tloss: 133224.375\n",
      "Iter: 713/780\tloss: 133309.531\n",
      "Iter: 714/780\tloss: 131376.031\n",
      "Iter: 715/780\tloss: 141272.969\n",
      "Iter: 716/780\tloss: 127024.289\n",
      "Iter: 717/780\tloss: 133915.688\n",
      "Iter: 718/780\tloss: 135463.609\n",
      "Iter: 719/780\tloss: 128085.672\n",
      "Iter: 720/780\tloss: 128363.586\n",
      "Iter: 721/780\tloss: 134004.516\n",
      "Iter: 722/780\tloss: 131359.172\n",
      "Iter: 723/780\tloss: 128265.039\n",
      "Iter: 724/780\tloss: 131390.297\n",
      "Iter: 725/780\tloss: 127165.023\n",
      "Iter: 726/780\tloss: 135072.516\n",
      "Iter: 727/780\tloss: 125347.906\n",
      "Iter: 728/780\tloss: 133933.781\n",
      "Iter: 729/780\tloss: 121133.516\n",
      "Iter: 730/780\tloss: 124225.000\n",
      "Iter: 731/780\tloss: 128803.094\n",
      "Iter: 732/780\tloss: 128443.367\n",
      "Iter: 733/780\tloss: 130852.602\n",
      "Iter: 734/780\tloss: 128434.664\n",
      "Iter: 735/780\tloss: 131022.484\n",
      "Iter: 736/780\tloss: 125833.602\n",
      "Iter: 737/780\tloss: 126563.180\n",
      "Iter: 738/780\tloss: 132638.641\n",
      "Iter: 739/780\tloss: 133356.797\n",
      "Iter: 740/780\tloss: 131071.430\n",
      "Iter: 741/780\tloss: 141092.719\n",
      "Iter: 742/780\tloss: 126769.555\n",
      "Iter: 743/780\tloss: 134240.938\n",
      "Iter: 744/780\tloss: 135215.875\n",
      "Iter: 745/780\tloss: 128219.359\n",
      "Iter: 746/780\tloss: 129027.188\n",
      "Iter: 747/780\tloss: 133658.516\n",
      "Iter: 748/780\tloss: 131329.906\n",
      "Iter: 749/780\tloss: 128337.562\n",
      "Iter: 750/780\tloss: 131311.203\n",
      "Iter: 751/780\tloss: 126825.656\n",
      "Iter: 752/780\tloss: 135114.203\n",
      "Iter: 753/780\tloss: 125186.844\n",
      "Iter: 754/780\tloss: 133434.859\n",
      "Iter: 755/780\tloss: 120515.773\n",
      "Iter: 756/780\tloss: 124718.234\n",
      "Iter: 757/780\tloss: 128046.297\n",
      "Iter: 758/780\tloss: 128524.922\n",
      "Iter: 759/780\tloss: 131214.047\n",
      "Iter: 760/780\tloss: 128531.625\n",
      "Iter: 761/780\tloss: 130856.102\n",
      "Iter: 762/780\tloss: 125988.531\n",
      "Iter: 763/780\tloss: 126389.898\n",
      "Iter: 764/780\tloss: 132970.062\n",
      "Iter: 765/780\tloss: 133472.281\n",
      "Iter: 766/780\tloss: 130943.172\n",
      "Iter: 767/780\tloss: 140714.938\n",
      "Iter: 768/780\tloss: 126576.320\n",
      "Iter: 769/780\tloss: 134191.531\n",
      "Iter: 770/780\tloss: 135554.188\n",
      "Iter: 771/780\tloss: 128444.695\n",
      "Iter: 772/780\tloss: 128458.406\n",
      "Iter: 773/780\tloss: 134001.703\n",
      "Iter: 774/780\tloss: 131469.688\n",
      "Iter: 775/780\tloss: 128754.195\n",
      "Iter: 776/780\tloss: 131726.156\n",
      "Iter: 777/780\tloss: 127275.328\n",
      "Iter: 778/780\tloss: 135515.328\n",
      "Iter: 779/780\tloss: 125428.898\n",
      "Iter: 780/780\tloss: 133483.984\n"
     ]
    }
   ],
   "source": [
    "num_iter_per_epoch = len(train_loader)\n",
    "maxiter = num_iter_per_epoch * num_epochs\n",
    "\n",
    "total_iter = 0\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for minibatch_i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        total_iter += 1\n",
    "        \n",
    "        deep_gp.zero_grad()\n",
    "        loss = torch.tensor(svi.step(x_batch, y_batch))\n",
    "        print(\n",
    "            f\"Iter: {total_iter}/{maxiter}\\t\"\n",
    "            f\"loss: {loss.item():.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.matmul(A, B)\n",
    "# A = b1 x b2 ... bk x n x m\n",
    "# B = 1 x 1 x ... x bk x m x k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
